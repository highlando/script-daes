<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Numerical Approximation of DAEs | DAEs</title>
  <meta name="description" content="Script to my DAE course at the OVGU in Fall 2018 / Spring 2021" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Numerical Approximation of DAEs | DAEs" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://www.janheiland.de/script-daes/" />
  
  <meta property="og:description" content="Script to my DAE course at the OVGU in Fall 2018 / Spring 2021" />
  <meta name="github-repo" content="highlando/script-daes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Numerical Approximation of DAEs | DAEs" />
  
  <meta name="twitter:description" content="Script to my DAE course at the OVGU in Fall 2018 / Spring 2021" />
  

<meta name="author" content="Jan Heiland" />


<meta name="date" content="2021-06-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="IV.html"/>
<link rel="next" href="construction-and-analysis-of-rkm-for-nonlinear-daes.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">DAEs</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#examples"><i class="fa fa-check"></i><b>1.1</b> Examples</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#why-are-daes-difficult-to-treat"><i class="fa fa-check"></i><b>1.2</b> Why are DAEs difficult to treat</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basic-definitions-and-notions.html"><a href="basic-definitions-and-notions.html"><i class="fa fa-check"></i><b>2</b> Basic Definitions and Notions</a><ul>
<li class="chapter" data-level="2.1" data-path="basic-definitions-and-notions.html"><a href="basic-definitions-and-notions.html#solution-concept"><i class="fa fa-check"></i><b>2.1</b> Solution Concept</a></li>
<li class="chapter" data-level="2.2" data-path="basic-definitions-and-notions.html"><a href="basic-definitions-and-notions.html#initial-conditions-and-consistency"><i class="fa fa-check"></i><b>2.2</b> Initial Conditions and Consistency</a></li>
<li class="chapter" data-level="2.3" data-path="basic-definitions-and-notions.html"><a href="basic-definitions-and-notions.html#additional-remarks"><i class="fa fa-check"></i><b>2.3</b> Additional Remarks</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="III.html"><a href="III.html"><i class="fa fa-check"></i><b>3</b> Linear DAEs with Constant Coefficients</a><ul>
<li class="chapter" data-level="3.1" data-path="III.html"><a href="III.html#basic-notions-and-definitions"><i class="fa fa-check"></i><b>3.1</b> Basic Notions and Definitions</a></li>
<li class="chapter" data-level="3.2" data-path="III.html"><a href="III.html#regularity-and-solvability"><i class="fa fa-check"></i><b>3.2</b> Regularity and Solvability</a></li>
<li class="chapter" data-level="3.3" data-path="III.html"><a href="III.html#solution-to-the-n-dae-regularity-and-index-of-a-matrix-pair"><i class="fa fa-check"></i><b>3.3</b> Solution to the <em>N-DAE</em>, Regularity, and Index of a Matrix Pair</a></li>
<li class="chapter" data-level="3.4" data-path="III.html"><a href="III.html#III-ex-sols"><i class="fa fa-check"></i><b>3.4</b> Existence of Solutions</a></li>
<li class="chapter" data-level="3.5" data-path="III.html"><a href="III.html#a-variation-of-constant-formula"><i class="fa fa-check"></i><b>3.5</b> A Variation of Constant Formula</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="IV.html"><a href="IV.html"><i class="fa fa-check"></i><b>4</b> Linear DAEs with Time-varying Coefficients</a><ul>
<li class="chapter" data-level="4.1" data-path="IV.html"><a href="IV.html#a-local-canonical-form"><i class="fa fa-check"></i><b>4.1</b> A Local Canonical Form</a></li>
<li class="chapter" data-level="4.2" data-path="IV.html"><a href="IV.html#IV-Global-Canonical-Form"><i class="fa fa-check"></i><b>4.2</b> A Global Canonical Form</a></li>
<li class="chapter" data-level="4.3" data-path="IV.html"><a href="IV.html#the-strangeness-index"><i class="fa fa-check"></i><b>4.3</b> The Strangeness Index</a></li>
<li class="chapter" data-level="4.4" data-path="IV.html"><a href="IV.html#derivative-arrays"><i class="fa fa-check"></i><b>4.4</b> Derivative Arrays</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="numerical-approximation-of-daes.html"><a href="numerical-approximation-of-daes.html"><i class="fa fa-check"></i><b>5</b> Numerical Approximation of DAEs</a><ul>
<li class="chapter" data-level="5.1" data-path="numerical-approximation-of-daes.html"><a href="numerical-approximation-of-daes.html#Vi"><i class="fa fa-check"></i><b>5.1</b> Notions and Notations</a></li>
<li class="chapter" data-level="5.2" data-path="numerical-approximation-of-daes.html"><a href="numerical-approximation-of-daes.html#runge-kutta-methods-for-linear-daes-with-constant-coefficients"><i class="fa fa-check"></i><b>5.2</b> Runge-Kutta Methods for Linear DAEs with Constant Coefficients</a></li>
<li class="chapter" data-level="5.3" data-path="numerical-approximation-of-daes.html"><a href="numerical-approximation-of-daes.html#a-note-on-rkm-for-time-varying-daes"><i class="fa fa-check"></i><b>5.3</b> A Note on RKM for Time-Varying DAEs</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="construction-and-analysis-of-rkm-for-nonlinear-daes.html"><a href="construction-and-analysis-of-rkm-for-nonlinear-daes.html"><i class="fa fa-check"></i><b>6</b> Construction and Analysis of RKM for nonlinear DAEs</a><ul>
<li class="chapter" data-level="6.1" data-path="construction-and-analysis-of-rkm-for-nonlinear-daes.html"><a href="construction-and-analysis-of-rkm-for-nonlinear-daes.html#general-rkm-for-semi-explicit-strangeness-free-daes"><i class="fa fa-check"></i><b>6.1</b> General RKM for Semi-Explicit Strangeness-free DAEs</a></li>
<li class="chapter" data-level="6.2" data-path="construction-and-analysis-of-rkm-for-nonlinear-daes.html"><a href="construction-and-analysis-of-rkm-for-nonlinear-daes.html#collocation-rkm-for-implicit-strangeness-free-daes"><i class="fa fa-check"></i><b>6.2</b> Collocation RKM for Implicit Strangeness-free DAEs</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="examples-1.html"><a href="examples-1.html"><i class="fa fa-check"></i><b>7</b> Examples</a><ul>
<li class="chapter" data-level="7.1" data-path="examples-1.html"><a href="examples-1.html#semi-discrete-navier-stokes-equations"><i class="fa fa-check"></i><b>7.1</b> Semi-discrete Navier-Stokes equations</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>8</b> Exercises</a><ul>
<li class="chapter" data-level="8.1" data-path="exercises.html"><a href="exercises.html#ii.c.1"><i class="fa fa-check"></i><b>8.1</b> II.C.1</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="numerical-analysis-and-software-overview.html"><a href="numerical-analysis-and-software-overview.html"><i class="fa fa-check"></i><b>9</b> Numerical Analysis and Software Overview</a><ul>
<li class="chapter" data-level="9.1" data-path="numerical-analysis-and-software-overview.html"><a href="numerical-analysis-and-software-overview.html#theory-rkms-and-bdf-for-daes"><i class="fa fa-check"></i><b>9.1</b> Theory: RKMs and BDF for DAEs</a></li>
<li class="chapter" data-level="9.2" data-path="numerical-analysis-and-software-overview.html"><a href="numerical-analysis-and-software-overview.html#solvers"><i class="fa fa-check"></i><b>9.2</b> Solvers</a></li>
<li class="chapter" data-level="9.3" data-path="numerical-analysis-and-software-overview.html"><a href="numerical-analysis-and-software-overview.html#software"><i class="fa fa-check"></i><b>9.3</b> Software</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DAEs</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="numerical-approximation-of-daes" class="section level1">
<h1><span class="header-section-number">5</span> Numerical Approximation of DAEs</h1>
<div id="Vi" class="section level2">
<h2><span class="header-section-number">5.1</span> Notions and Notations</h2>
<p>We will consider an equidistant time grid of a fixed time interval <span class="math inline">\([t_0,t_e]\)</span>:
<span class="math display">\[
t_0 &lt; t_1 &lt; t_2 &lt; \dotsm &lt; t_N=t_e
\]</span>
with time step size <span class="math inline">\(h\)</span>, i.e. <span class="math inline">\(t_i = t_0 + ih\)</span>, for <span class="math inline">\(i=1,2,\dotsc,N\)</span>, or <span class="math inline">\(h=\frac{t_e - t_0}{N}\)</span>.</p>

<div class="JHSAYS">
<p>The restriction of equidistant grids is convenient for the analysis and does not mean a great loss of generality. Typically, in all the estimates that follow and in which the <em>constants</em> remain unspecified, a non equidistant grid can be accommodated by setting <span class="math inline">\(h\)</span> to be the largest time step under consideration.</p>
In practice, however, one really uses adaptive and, thus, nonuniform time grids.
</div>

<p>Throughout this chapter, we will assume that system under consideration has a unique solution <span class="math inline">\(x\)</span> and we will use the notation
<span class="math display">\[
x_i \approx x(t_i)
\]</span>
to express that <span class="math inline">\(x_i\)</span> is defined as the numerically computed approximation to the solution <span class="math inline">\(x\)</span> at time <span class="math inline">\(t_i\)</span>.</p>

<div class="JHSAYS">
It is unfortunate that <span class="math inline">\(x_i\)</span> has been used to denote parts of the actual solution, but I hope this inconsistency can be tolerated in favor of a more pleasant and more standard notation.
</div>

<p>Generally, the approximants <span class="math inline">\(x_i\)</span> are computed iteratively by a numerical scheme <span class="math inline">\(\phi\)</span> like
<span class="math display" id="eq:v-one-step-scheme">\[
x_{i+1} = \phi(t_i,h,x_i,x_{i+1}). \tag{5.1}
\]</span>
If <span class="math inline">\(x_{i+1}\)</span> appears in the definition of the function <span class="math inline">\(\phi\)</span>, then the scheme is called <em>implicit</em>. Otherwise, it is called an explicit scheme. If the scheme bases on previous iterates like <span class="math inline">\(x_{i-1}\)</span>, <span class="math inline">\(x_{i-2}\)</span>, …, <span class="math inline">\(x_{i-k}\)</span> with <span class="math inline">\(k\geq 0\)</span>, then the scheme is called a <em>multi-step scheme</em>. Otherwise, it is called a <em>single-step scheme</em>.</p>
<p>Generally, the analysis of the schemes and their application to problem classes tries to establish convergence, e.g.,
<span class="math display">\[
\|x_N - x(t_e)\| \to 0
\]</span>
as <span class="math inline">\(h \to 0\)</span>. More precisely, tries to establish estimates like
<span class="math display">\[
x_N - x(t_e) = \mathcal O(h^p)
\]</span>
meaning that the error approaches <span class="math inline">\(0\)</span> at least as fast as the convergence order <span class="math inline">\(p\)</span>. This <span class="math inline">\(p\)</span> is then called the <em>order of convergence</em> (of the method <span class="math inline">\(\phi\)</span>).</p>
<p>If the method <span class="math inline">\(\phi\)</span> is stable<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>, then an estimate on the (local) consistency error (cp. the definition of the iteration <a href="numerical-approximation-of-daes.html#eq:v-one-step-scheme">(5.1)</a>) like
<span class="math display">\[
x(t_{i+1}) - \phi(t_i, h, x(t_i), x(t_{i+1})) = \mathcal O(h^q),
\]</span>
i.e. the <em>order of consistency</em> of <span class="math inline">\(\phi\)</span>, transfers to the global convergence order as <span class="math inline">\(p=q-1\)</span>.</p>
<p>We will start with one-step methods and in particular with Runge-Kutta methods (RKM) that represent the most commonly applied time discretization schemes. A Runge-Kutta method is defined by its number of stages <span class="math inline">\(s\)</span>, and by parameter vectors
<span class="math display">\[
\beta = \{\beta_j\}_{j=1, \dotsc, s}, \quad \gamma=\{\gamma_j\}_{j=1,\dotsc,s}, \quad 
\mathcal A = \{\alpha_{j\ell}\}_{j,\ell=1, \dotsc, s}
\]</span>
that, in turn, define the increment <span class="math inline">\(x_{i+1}=\phi(t_i,h,x_i,x_{i+1})\)</span> via
<span class="math display">\[
x_{i+1}=x_i+h\sum_{j=1}^s\beta_j \dot X_{ij},
\]</span>
where the <em>stage derivatives</em> <span class="math inline">\(\dot X_{ij}\)</span> are connected with the <em>stage values</em> <span class="math inline">\(X_{ij}\)</span> via the following possibly nonlinear (depending on the problem: <span class="math inline">\(\dot x(t) = f(t,x(t))\)</span>) and possibly implicit (depending on the method) system of equations
<span class="math display">\[\begin{align}
\dot X_{ij} &amp;= f(t_i+\gamma_jh, X_{ij}), \\
X_{ij} &amp;= x_i + h \sum_{j=1}^s \alpha_{j\ell} \dot X_{i\ell}.
\end{align}\]</span></p>
<p>The matrix <span class="math inline">\(\mathcal A\)</span> and the vectors <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\gamma\)</span> of parameters are conveniently written into the so-called <em>Butcher-tableau</em>
<span class="math display">\[
\begin{array}{c|c}
 \gamma &amp; \mathcal A \\
 \hline
  &amp; \beta^T \\
\end{array}
\]</span></p>
<p>It is well-known that one-step methods are stable (see also the first paragraph of Kunkel/Mehrmann Ch. 5.2). Accordingly, convergence can be derived directly from the consistency error. For a general Runge-Kutta method, the convergence conditions – if applied to an ODE <span class="math inline">\(\dot x = f(t,x)\)</span> – can be expressed in terms of the coefficients:</p>

<div class="theorem">
<p><span id="thm:v-butcher" class="theorem"><strong>Theorem 5.1  (Butcher’s Theorem)  </strong></span>If the coefficients <span class="math inline">\(\beta_j\)</span>, <span class="math inline">\(\gamma_j\)</span>, and <span class="math inline">\(\alpha_{j\ell}\)</span> fulfill the conditions</p>
<table>
<colgroup>
<col width="8%" />
<col width="57%" />
<col width="34%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">Condition</th>
<th align="left">range of <span class="math inline">\(k\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">B(p):</td>
<td align="left"><span class="math inline">\(\sum_{j=1}^s\beta_j\gamma_j^{k-1} = \frac 1k\)</span></td>
<td align="left"><span class="math inline">\(k=1,2,\cdots,p\)</span></td>
</tr>
<tr class="even">
<td align="left">C(q):</td>
<td align="left"><span class="math inline">\(\sum_{\ell=1}^s\alpha_{j\ell}\gamma_\ell^{k-1} = \frac 1k\gamma_j^k,\quad\)</span> for <span class="math inline">\(j=1,\dotsc s\)</span></td>
<td align="left"><span class="math inline">\(k=1,2,\cdots,q\)</span></td>
</tr>
<tr class="odd">
<td align="left">D(r):</td>
<td align="left"><span class="math inline">\(\sum_{j=1}^s\beta_j\gamma_j^{k-1} \alpha_{j\ell}= \frac 1k\beta_\ell(1-\gamma_\ell^k),\quad\)</span> for <span class="math inline">\(\ell=1,\dotsc s\)</span></td>
<td align="left"><span class="math inline">\(k=1,2,\cdots,r\)</span></td>
</tr>
</tbody>
</table>
<p>with
<span class="math display">\[ p\leq q+r+1 \]</span> and <span class="math display">\[ p \leq 2q+2,\]</span> then the Runge-Kutta method is convergent of order <span class="math inline">\(p\)</span>.</p>
</div>


<div class="JHSAYS">
Knowing that one-step methods are stable, one typically examines only the consistency error for the approximation of ODEs. For DAEs, however, we will have to identify stable RKM methods.
</div>

<p>In particular for the analysis of the approximation of linear DAEs, the Kronecker product <span class="math inline">\(\otimes\)</span> and two of its properties will be helpful:</p>

<div class="definition">
<span id="def:v-kronecker-product" class="definition"><strong>Definition 5.1  </strong></span>For two matrices <span class="math inline">\(U \in \mathbb C^{m,n}\)</span> and <span class="math inline">\(V\in \mathbb C^{k,l}\)</span>, with
<span class="math display">\[
U = 
\begin{bmatrix}
u_{11} &amp; \dots &amp; u_{1n} \\
\vdots &amp; \ddots &amp; \vdots \\
u_{m1} &amp; \dots &amp; u_{mn}
\end{bmatrix}
\]</span>
their <em>Kronecker product</em> <span class="math inline">\(U \otimes V\)</span> is defined as
<span class="math display">\[
U\otimes V = 
\begin{bmatrix}
u_{11}V &amp; \dots &amp; u_{1n}V \\
\vdots &amp; \ddots &amp; \vdots \\
u_{m1}V &amp; \dots &amp; u_{mn}V
\end{bmatrix}
\in \mathbb C^{mk, nl}.
\]</span>
</div>


<div class="lemma">
<span id="lem:v-kronecker-perfect-shuffle" class="lemma"><strong>Lemma 5.1  </strong></span>For given dimensions <span class="math inline">\(m\)</span>, <span class="math inline">\(n\)</span>, <span class="math inline">\(k\)</span>, <span class="math inline">\(l\)</span>, there exist permutations matrices
<span class="math display">\[
\Pi_1 \in \mathbb R^{mk, mk}, \quad \Pi_2 \in \mathbb C^{kl, kl},
\]</span>
so that for any matrices <span class="math inline">\(U \in \mathbb C^{m,n}\)</span> and <span class="math inline">\(V\in \mathbb C^{k,l}\)</span> it holds that
<span class="math display">\[
U\otimes V = \Pi_1^T (V\otimes U) \Pi_2.
\]</span>
If <span class="math inline">\(n=m\)</span> and <span class="math inline">\(k=l\)</span>, then <span class="math inline">\(\Pi_1=\Pi_2\)</span>.
</div>

<p>Note that the inverse of a permutation matrix <span class="math inline">\(\Pi\)</span> is its transpose <span class="math inline">\(\Pi^T\)</span>, so that for square matrices <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> with <span class="math inline">\(\Pi_1=\Pi_2=:\Pi\)</span>, it holds that
<span class="math display">\[
U\otimes V = \Pi^T(V\otimes U)\Pi \sim V\otimes U.
\]</span></p>

<div class="lemma">
<span id="lem:v-kronecker-associativity" class="lemma"><strong>Lemma 5.2  </strong></span>If the given matrices <span class="math inline">\(R\)</span>, <span class="math inline">\(S\)</span>, <span class="math inline">\(U\)</span>, <span class="math inline">\(V\)</span> have compatible dimensions so that the products <span class="math inline">\(UR\)</span> and <span class="math inline">\(VS\)</span> exist, then
<span class="math display">\[
(U\otimes V)(R\otimes S) = UR \otimes VS.
\]</span>
</div>

</div>
<div id="runge-kutta-methods-for-linear-daes-with-constant-coefficients" class="section level2">
<h2><span class="header-section-number">5.2</span> Runge-Kutta Methods for Linear DAEs with Constant Coefficients</h2>
<p>In this section, we will analyse the approximation error of the RKM <span class="math inline">\((\mathcal A, \beta, \gamma)\)</span> applied to a regular linear DAE with constant coefficients</p>
<p><span class="math display" id="eq:v-lin-dae-cc">\[
 E\dot x = Ax+f(t). \tag{5.2}
\]</span></p>
<p>To motivate the following arguments and assumptions, we just try to apply the <em>explicit Euler</em> to <a href="numerical-approximation-of-daes.html#eq:v-lin-dae-cc">(5.2)</a> so that a single iteration step reads
<span class="math display">\[
Ex_{i+1} = Ex_i + h(Ax_i + f(t_i)),
\]</span>
which can not fully define <span class="math inline">\(x_{i+1}\)</span> if <span class="math inline">\(E\)</span> is not invertible.</p>
<p>On the other hand, if <span class="math inline">\((E,A)\)</span> is regular, then one step of the <em>implicit Euler</em> scheme,
<span class="math display">\[
(E-hA)x_{i+1} = Ex_i + hf(t_i),
\]</span>
well defines the next iterate for any choice of <span class="math inline">\(h\)</span> except a few.</p>
<p>In more generality, a complete iteration step of a general RKM applied to <a href="numerical-approximation-of-daes.html#eq:v-lin-dae-cc">(5.2)</a>, can be expressed via the solution<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> of the linear system</p>
<p><span class="math display">\[
(I_s \otimes E - h\mathcal A \otimes A) \dot X_i = Z_i
\]</span>
with
<span class="math display">\[
\dot X_i = 
\begin{bmatrix}
\dot X_{i1} \\ \vdots \\ \dot X_{is}
\end{bmatrix}, \quad
\dot Z_i = 
\begin{bmatrix}
Ax_{i}+f(t_i+\gamma_1h) \\ \vdots \\ Ax_{i}+f(t_i+\gamma_sh)
\end{bmatrix}
\]</span>
If <span class="math inline">\((E, A)\)</span> is regular, and <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> are those matrices that bring <span class="math inline">\((E,A)\)</span> into Kronecker normal form, then, with Lemma <a href="numerical-approximation-of-daes.html#lem:v-kronecker-associativity">5.2</a>, we can find that
<span class="math display">\[
(I_s\otimes P)(I_s \otimes E - h\mathcal A \otimes A)(I_s \otimes Q) = (I_s \otimes PEQ - h(\mathcal A \otimes PAQ))
\]</span>
which by Lemma <a href="numerical-approximation-of-daes.html#lem:v-kronecker-perfect-shuffle">5.1</a> is similar to
<span class="math display">\[
PEQ\otimes I_s - PAQ \otimes h\mathcal A = 
\begin{bmatrix}
I \otimes I_s &amp; \\ &amp; N\otimes I_s
\end{bmatrix}
- h
\begin{bmatrix}
J \otimes \mathcal A &amp; \\ &amp; I\otimes \mathcal A 
\end{bmatrix},
\]</span>
which means that for a regular DAE, one step of an RKM can be interpreted as one step of an RKM for the ODE and one step for the DAE part in the canonical form.</p>
<p>As for the invertibility of the coefficient matrix, we first observe that for <span class="math inline">\(h\)</span> sufficiently small, the part <span class="math inline">\(I\otimes I_s - hJ\otimes \mathcal A\)</span> is invertible. For the second part, we assume that <span class="math inline">\(N\)</span> is in Jordan form and consists of only one block (otherwise the arguments can be formulated for each block separately) to find that
<span class="math display">\[
N\otimes I_s - I \otimes h \mathcal A = 
\begin{bmatrix}
-h\mathcal A &amp; I_s \\
&amp; \ddots &amp; \ddots \\
&amp;&amp; -h\mathcal A &amp; I_s \\
&amp;&amp;&amp; -h\mathcal A
\end{bmatrix}
\]</span>
is invertible if, and only if, <span class="math inline">\(\mathcal A\)</span> is invertible.</p>

<div class="JHSAYS">
Generally, the numerical solution of DAEs requires implicit schemes.
</div>

<p>By the previous considerations, the following assumptions are well justified – at least for the theoretical analysis of the schemes.</p>
<ul>
<li><span class="math inline">\((E,A)\)</span> is regular <span class="math inline">\(\leftarrow\)</span> the theory needs a unique solution</li>
<li><span class="math inline">\((E,A)\)</span> is in Kronecker Canonical Form <span class="math inline">\(\leftarrow\)</span> RKM are invariant under equivalence transformation</li>
<li><span class="math inline">\((E,A)=(N,I)\)</span> <span class="math inline">\(\leftarrow\)</span> the <em>regular part</em> can be treated by ODE theory</li>
<li><span class="math inline">\(E=N=N_\nu\)</span> consists of a single Jordan block <span class="math inline">\(\leftarrow\)</span> otherwise consider each Jordan block separately.</li>
</ul>
<p>Thus, we will consider the special DAE</p>
<p><span class="math display" id="eq:spec-dae-rkm-cc">\[\begin{equation}
\begin{bmatrix}
0 &amp; 1 &amp;        &amp;         &amp;    \\
  &amp; 0 &amp; 1      &amp;         &amp;    \\
  &amp;   &amp; \ddots &amp; \ddots  &amp;    \\
  &amp;   &amp;        &amp; 0       &amp; 1  \\
  &amp;   &amp;        &amp;         &amp; 0 
\end{bmatrix}
\dot x = x + f(t),
\tag{5.3}
\end{equation}\]</span></p>
<p>where</p>
<p><span class="math display">\[
 x(t) = \begin{bmatrix} x_1(t) \\ x_2(t) \\ \vdots \\ x_\nu(t) \end{bmatrix}
 \quad\text{and}\quad
 f(t) = \begin{bmatrix} f_1(t) \\ f_2(t) \\ \vdots \\ f_\nu(t) \end{bmatrix}
 \]</span></p>

<div class="JHSAYS">
Please excuse the double use of the subscript like in <span class="math inline">\(x_1\)</span>.
</div>

<p>In the following theorem, the consistency error of a general implicit RKM applied to the special nilpotent DAE is analysed.</p>

<div class="theorem">
<p><span id="thm:v-local-consistency-error-rkm-lcc" class="theorem"><strong>Theorem 5.2  </strong></span>The local error of an RKM with <span class="math inline">\(\mathcal A\)</span> invertible applied to <a href="numerical-approximation-of-daes.html#eq:spec-dae-rkm-cc">(5.3)</a> behaves like</p>
<p><span class="math display">\[
x(t_{i+1}) - x_{i+1} = \mathcal O(h^{\kappa_\nu - \nu + 2} + h^{\kappa_{\nu-1} - \nu + 3} + \cdots + h^{\kappa_1 +1})
\]</span></p>
<p>where <span class="math inline">\(\kappa_j\)</span> is the maximum number such that</p>
<table>
<colgroup>
<col width="8%" />
<col width="57%" />
<col width="34%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">Condition</th>
<th align="left">range of <span class="math inline">\(k\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">a.)</td>
<td align="left"><span class="math inline">\(\beta^T\mathcal A^{-k}e = \beta^T\mathcal A^{-j}\gamma^{j-k} / (j-k)!\)</span></td>
<td align="left"><span class="math inline">\(k=1,2,\cdots,j-1\)</span></td>
</tr>
<tr class="even">
<td align="left">b.)</td>
<td align="left"><span class="math inline">\(\beta^T\mathcal A^{-j}\gamma^k = k! / (k-j+1)!\)</span></td>
<td align="left"><span class="math inline">\(k=j,j+1,\cdots\)</span></td>
</tr>
</tbody>
</table>
<p>for all <span class="math inline">\(k\leq \kappa_j\)</span> and for <span class="math inline">\(j=1, \cdots, \nu\)</span> and where <span class="math inline">\(e\in \mathbb R^{\nu}\)</span> is the vector of ones.</p>
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> Since we consider the pure consistency error, we can assume that <span class="math inline">\(x_i=x(t_i)\)</span>. With that, with the Taylor expansion of the solution
<span class="math display">\[
x(t_{i+1}) = x(t_i+h) = x(t_i) + \sum_{k\geq 1} \frac{h^k}{k!}x^{(k)}(t_i),
\]</span>
and with the definition of the RKM, the error is given as
<span class="math display">\[
\tau = x(t_{i+1}) - x_{i+1} = -h\sum_{j=1}^s \beta_j \dot X_{ij} + \sum_{k\geq 1} \frac{h^k}{k!}x^{(k)}(t_i).
\]</span></p>
<p>Because of the special structure of the DAE, we can concentrate on the first error component <span class="math inline">\(\tau_1\)</span> <span class="math inline">\(\leftarrow\)</span> the error component <span class="math inline">\(\tau_2\)</span> is the <em>first</em> component of the problem of index <span class="math inline">\(\nu-1\)</span>. For <span class="math inline">\(\tau_1\)</span> we have the formula</p>
<p><span class="math display">\[
\tau_1 = x_1(t_{i+1}) - x_{i+1,1} = h\beta^T\sum_{j=1}^\nu (h\mathcal A)^{-j}Z_{ij} + \sum_{k\geq 1} \frac{h^k}{k!}x_1^{(k)}(t_i).
\]</span></p>
<p>One may confirm directly, or by means of the solution formula for <span class="math inline">\(N\dot x = x + f\)</span>, that the <span class="math inline">\(\ell\)</span>-th component of <span class="math inline">\(x\)</span> is defined as
<span class="math display">\[
x_\ell(t) = - \sum_{j=\ell}^{\nu}f_j^{(j-\ell)}(t).
\]</span></p>
<p>The componentwise Taylor expansion of <span class="math inline">\(Z_{i,\ell}\)</span> reads
<span class="math display">\[\begin{align*}
Z_{i\ell} 
&amp;= 
\begin{bmatrix}
x_{i,\ell} + f_\ell(t_i+\gamma_1 h) \\
x_{i,\ell} + f_\ell(t_i+\gamma_2 h) \\
\vdots \\
x_{i,\ell} + f_\ell(t_i+\gamma_s h) 
\end{bmatrix}
=
\begin{bmatrix}
    x_{i,\ell} + f_\ell(t_i) + \sum_{k\geq 1}\frac{h^k}{k!}f_\ell^{(k)}(t_i)\gamma_1^k \\
  x_{i,\ell} + f_\ell(t_i) + \sum_{k\geq 1}\frac{h^k}{k!}f_\ell^{(k)}(t_i)\gamma_2 ^k \\
\vdots \\
  x_{i,\ell} + f_\ell(t_i) + \sum_{k\geq 1}\frac{h^k}{k!}f_\ell^{(k)}(t_i)\gamma_s ^k 
\end{bmatrix} \\
&amp;=
x_{i,\ell}e+\sum_{k\geq 0} \frac{h^k}{k!}f_\ell^{(k)}(t_i)\gamma^k
\end{align*}\]</span></p>
<p>With that and with <span class="math inline">\(x_i=x(t_i)\)</span>, we expand the error <span class="math inline">\(\tau_1\)</span> as follows:
<span class="math display">\[\begin{align*}
\tau_1 &amp;= \beta^T\sum_{j=1}^\nu (h\mathcal A)^{-j}Z_{ij} + \sum_{k\geq 1} \frac{h^k}{k!}x_1^{(k)}(t_i)\\
&amp;= \beta^T\sum_{j=1}^\nu h^{-j+1}\mathcal A^{-j}\bigr[ x_{j}(t_i)e+\sum_{k\geq 0} \frac{h^k}{k!}f_j^{(k)}(t_i)\gamma^k\bigr] \\&amp;\quad\quad\quad\quad+ \sum_{k\geq 1} \frac{h^k}{k!}x_1^{(k)}(t_i)\\
&amp;= \beta^T\sum_{j=1}^\nu h^{-j+1}\mathcal A^{-j}\bigr[ -\sum_{k=j}^{\nu}f_k^{(k-j)}(t_i)e+\sum_{k\geq 0} \frac{h^k}{k!}f_j^{(k)}(t_i)\gamma^k\bigr] \\&amp;\quad\quad\quad\quad- \sum_{k\geq 1} \frac{h^k}{k!} \sum_{j=1}^{\nu}f_j^{(j-1+k)}(t_i)\\
&amp;= -\sum_{j=1}^\nu \sum_{k=j}^{\nu} h^{-j+1}\beta^T\mathcal A^{-j} ef_k^{(k-j)}(t_i)+\sum_{j=1}^\nu \sum_{k\geq 0}\frac{h^{k-j+1}}{k!}\beta^T\mathcal A^{-j} \gamma^k f_j^{(k)}(t_i) \\&amp;\quad\quad\quad\quad- \sum_{k\geq 1}\sum_{j=1}^{\nu} \frac{h^k}{k!} f_j^{(j-1+k)}(t_i),
\end{align*}\]</span></p>
<p>which, with <span class="math inline">\(\sum_{j=1}^\nu \sum_{k=j}^\nu g(j,k) = \sum_{k=1}^\nu \sum_{j=1}^k g(j,k)= \sum_{k=1}^\nu \sum_{j=1}^k g(k,j)\)</span>, becomes</p>
<p><span class="math display">\[\begin{align*}
\tau_1 &amp;= \sum_{j=1}^{\nu} \bigl[ -\sum_{k=1}^j h^{-k+1}\beta^T\mathcal A^{-k} ef_k^{(j-k)}(t_i)\\&amp;\quad\quad\quad\quad+\sum_{k\geq 0}\frac{h^{k-j+1}}{k!}\beta^T\mathcal A^{-j} \gamma^k f_j^{(k)}(t_i) \\&amp;\quad\quad\quad\quad- \sum_{k\geq 1}\frac{h^k}{k!} f_j^{(j-1+k)}(t_i) \bigr] \\
 &amp;= \sum_{j=1}^{\nu} \bigl[ -\sum_{k=1}^j h^{-k+1}\beta^T\mathcal A^{-k} ef_k^{(j-k)}(t_i)\\
 &amp;\quad\quad\quad\quad+\sum_{k=0}^{j-1}\frac{h^{k-j+1}}{k!}\beta^T\mathcal A^{-j} \gamma^k f_j^{(k)}(t_i)+\sum_{k\geq j}\frac{h^{k-j+1}}{k!}\beta^T\mathcal A^{-j} \gamma^k f_j^{(k)}(t_i) \\&amp;\quad\quad\quad\quad- \sum_{k\geq 1}\frac{h^k}{k!} f_j^{(j-1+k)}(t_i) \bigr].
\end{align*}\]</span></p>
<p>A shift of indices, <span class="math inline">\(\sum_{k=0}^{j-1}g(k)=\sum_{k=1}^j g(j-k)\)</span> and <span class="math inline">\(\sum_{k\geq 1}g(k)=\sum_{k\geq j}g(k-j+1)\)</span>, then gives:
<span class="math display">\[\begin{align*}
    \tau_1 &amp;= \sum_{j=1}^{\nu} \bigl[ -\sum_{k=1}^j h^{-k+1}\beta^T\mathcal A^{-k} ef_k^{(j-k)}(t_i)+\sum_{k=1}^{j}\frac{h^{-k+1}}{(j-k)!}\beta^T\mathcal A^{-j} \gamma^{j-k} f_j^{(j-k)}(t_i)\\ &amp;\quad\quad\quad\quad+\sum_{k\geq j}\frac{h^{k-j+1}}{k!}\beta^T\mathcal A^{-j} \gamma^k f_j^{(k)}(t_i) - \sum_{k\geq j}\frac{h^{k-j+1}}{(k-j+1)!} f_j^{(k)}(t_i) \bigr].
\end{align*}\]</span></p>
<p>and a comparison of the coefficients for the same orders of <span class="math inline">\(h\)</span> and diffentials of <span class="math inline">\(f\)</span> leads to the conditions. Note the ranges of the sums that depend on <span class="math inline">\(j=1, \dotsc, \nu\)</span>.</p>
</div>


<div class="JHSAYS">
Theorem <a href="numerical-approximation-of-daes.html#thm:v-local-consistency-error-rkm-lcc">5.2</a> was formulated for the special case of <span class="math inline">\(\dot x = Nx +f(t)\)</span>. By the preceding derivations, we have argumented, that it holds for the general largest nilpotent block of <span class="math inline">\(E\dot x = Ax+f(t)\)</span>. If one estimates the ODE parts as for standard ODEs and the <em>smaller</em> nilpotent blocks separately, the result can be formulated for the general case, as it is used in the theorem below.
</div>

<p>To prove convergence of the approximations another stability condition is added.</p>

<div class="theorem">
<span id="thm:v-convergence-RKM-LTI" class="theorem"><strong>Theorem 5.3  (Kunkel/Mehrmann, Thm. 5.12)  </strong></span>Consider an implicit RKM with coefficients <span class="math inline">\(\mathcal A\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\gamma\)</span> and a linear time invariant DAE <span class="math inline">\(E\dot x = Ax+f(t)\)</span> with <span class="math inline">\((E,A)\)</span> regular and of index <span class="math inline">\(\nu\)</span>. Let <span class="math inline">\(\kappa_j\)</span>, <span class="math inline">\(j=1,\dots,\nu\)</span>, be the quantities of <span class="math inline">\((\mathcal A,\beta, \gamma)\)</span> as defined in Theorem <a href="numerical-approximation-of-daes.html#thm:v-local-consistency-error-rkm-lcc">5.2</a> and assume that
<span class="math display" id="eq:v-RKM-stab-cond">\[\begin{equation}
| 1-\beta ^T\mathcal A^{-1}e| &lt; 1. \tag{5.4}
\end{equation}\]</span>
Then, the RKM is convergent of order
<span class="math display">\[\begin{equation}
\min_{1\leq j \leq \nu}\{p, \kappa_j - \nu +2\},
\end{equation}\]</span>
where <span class="math inline">\(p\)</span> is the order of the RKM when applied to ordinary differential equations.
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> See Kunkel/Mehrmann, Theorem 5.12.
</div>

<p>Some remarks on the <em>stability condition</em> <a href="numerical-approximation-of-daes.html#eq:v-RKM-stab-cond">(5.4)</a>. As laid out in the proof of the theorem, the quantity <span class="math inline">\(\rho = 1-\beta ^T\mathcal Ae\)</span> defines an amplification factor of the numerical errors. Accordingly, <span class="math inline">\(|\rho| &lt; 1\)</span> is one of the sufficient conditions for convergence. For <span class="math inline">\(\rho = 0\)</span>, utmost stability is reached which, as we will see below for the general nonlinear case, means that <em>index-1</em> (or <em>strangeness-free</em>) problems are integrated with the same order as ODEs.</p>
<p>For example, so-called <em>stiffly-implicit</em> schemes (we will consider them again at a later point in the lecture) come with the property that
<span class="math display">\[
\alpha_{sj} = \beta_j, \quad j=1,2,\dotsc,s,
\]</span>
i.e. the last row of the <span class="math inline">\(\mathcal A\)</span> matrix equals the vector <span class="math inline">\(\beta\)</span> or, in other terms,
<span class="math display">\[
\beta^T = e_s^T\mathcal A, \quad e_s^T:=
\begin{bmatrix}
0&amp; 0&amp; \dots &amp;1
\end{bmatrix},
\]</span>
so that
<span class="math display">\[
1-\beta^T\mathcal A^{-1}e= 1-e_s^T\mathcal A\mathcal A^{-1}e = 1-e_s^Te=1-1=0.
\]</span></p>
<p>If also <span class="math inline">\(\sum_{\ell=1}^s\alpha_{j\ell}=\gamma_j\)</span> (which is the case for all RKM that treat the autonomous case <span class="math inline">\(\dot x=f(x)\)</span> like the nonautonomous case <span class="math inline">\(\dot x=f(t,x)\)</span>) and since, for every consistent RKM, one has that <span class="math inline">\(\sum_{j=1}^s\beta_j=1\)</span> (cp. Butcher’s Theorem <a href="numerical-approximation-of-daes.html#thm:v-butcher">5.1</a>), we find that for such <em>stiffly accurate</em> RKM, necessarily
<span class="math display">\[\begin{equation}
\gamma_s =\sum_{\ell=1}^s\alpha_{s\ell} = \sum_{j=1}^s\beta_j=1.
\end{equation}\]</span></p>
<p>This implies that condition b.) in Theorem <a href="numerical-approximation-of-daes.html#thm:v-local-consistency-error-rkm-lcc">5.2</a> with <span class="math inline">\(j=1\)</span> is fulfilled for any <span class="math inline">\(k\)</span>, as
<span class="math display">\[
\beta^T\mathcal A^{-1}\gamma^k = e_s^T\gamma^k = \gamma_s^k = 1 = \frac{k\,!}{k\,!}.
\]</span></p>
<p>This means that <span class="math inline">\(\kappa_1=\infty\)</span> and, thus, no order reduction for problems of index <span class="math inline">\(\nu=1\)</span>.</p>
</div>
<div id="a-note-on-rkm-for-time-varying-daes" class="section level2">
<h2><span class="header-section-number">5.3</span> A Note on RKM for Time-Varying DAEs</h2>
<p>For a general linear time-varying DAE
<span class="math display">\[
E(t)\dot x = A(t)x +f(t),
\]</span>
the application of <em>Implicit Euler</em> as a general Runge-Kutta method reads
<span class="math display">\[
x_{i+1} = x_i + h\dot X_{i1}
\]</span>
with the stage derivative <span class="math inline">\(\dot X_{i1}\)</span> implicitly defined via
<span class="math display">\[\begin{align}
E(t_{i+1})\dot X_{i1} &amp;= A(t_{i+1})X_{i1} + f(t_{i+1}) \\
X_{i1} &amp;= x_i + h \dot X_{i1},
\end{align}\]</span>
which, with <span class="math inline">\(h \dot X_{i1}=X_{i1}-x_i\)</span> and <span class="math inline">\(X_{i1}=x_{i+1}\)</span> gives the system</p>
<p><span class="math display">\[
[E(t_{i+1})-hA(t_{i+1})]x_{i+1} = E(t_{i+1})x_i + hf(t_{i+1}).
\]</span>
If we compare with the examples from the chapter on linear time-varying DAEs, we need to record that</p>
<ul>
<li>if <span class="math inline">\((E(t), A(t))\)</span> is regular for all <span class="math inline">\(t\)</span>, then the RKM may return a unique solution despite the fact that there are infinitely many; cp. Example <a href="IV.html#exm:ltv-regular-infinite-sols">4.1</a></li>
<li>if <span class="math inline">\((E(t), A(t))\)</span> is singular for all <span class="math inline">\(t\)</span>, then the RKM cannot determine an approximation despite the fact that the problem has a unique solution; cp. Example <a href="IV.html#exm:ltv-singular-unique-sol">4.2</a>.</li>
</ul>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p><em>Stability</em> can be defined in many different ways. It basically means that small errors can be accumulated (that’s why the order of convergence is one less the the order of consistency) but are not amplified by the method. See e.g. Kunkel/Mehrmann Def. 5.2.<a href="numerical-approximation-of-daes.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>The proof is left as an exercise.<a href="numerical-approximation-of-daes.html#fnref7" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="IV.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="construction-and-analysis-of-rkm-for-nonlinear-daes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DAEs.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
