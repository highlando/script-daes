<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Linear DAEs with Time-varying Coefficients | DAEs</title>
  <meta name="description" content="Script to my DAE course at the OVGU in Fall 2018 / Spring 2021" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Linear DAEs with Time-varying Coefficients | DAEs" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://www.janheiland.de/script-daes/" />
  
  <meta property="og:description" content="Script to my DAE course at the OVGU in Fall 2018 / Spring 2021" />
  <meta name="github-repo" content="highlando/script-daes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Linear DAEs with Time-varying Coefficients | DAEs" />
  
  <meta name="twitter:description" content="Script to my DAE course at the OVGU in Fall 2018 / Spring 2021" />
  

<meta name="author" content="Jan Heiland" />


<meta name="date" content="2021-06-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="III.html"/>
<link rel="next" href="numerical-approximation-of-daes.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">DAEs</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#examples"><i class="fa fa-check"></i><b>1.1</b> Examples</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#why-are-daes-difficult-to-treat"><i class="fa fa-check"></i><b>1.2</b> Why are DAEs difficult to treat</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basic-definitions-and-notions.html"><a href="basic-definitions-and-notions.html"><i class="fa fa-check"></i><b>2</b> Basic Definitions and Notions</a><ul>
<li class="chapter" data-level="2.1" data-path="basic-definitions-and-notions.html"><a href="basic-definitions-and-notions.html#solution-concept"><i class="fa fa-check"></i><b>2.1</b> Solution Concept</a></li>
<li class="chapter" data-level="2.2" data-path="basic-definitions-and-notions.html"><a href="basic-definitions-and-notions.html#initial-conditions-and-consistency"><i class="fa fa-check"></i><b>2.2</b> Initial Conditions and Consistency</a></li>
<li class="chapter" data-level="2.3" data-path="basic-definitions-and-notions.html"><a href="basic-definitions-and-notions.html#additional-remarks"><i class="fa fa-check"></i><b>2.3</b> Additional Remarks</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="III.html"><a href="III.html"><i class="fa fa-check"></i><b>3</b> Linear DAEs with Constant Coefficients</a><ul>
<li class="chapter" data-level="3.1" data-path="III.html"><a href="III.html#basic-notions-and-definitions"><i class="fa fa-check"></i><b>3.1</b> Basic Notions and Definitions</a></li>
<li class="chapter" data-level="3.2" data-path="III.html"><a href="III.html#regularity-and-solvability"><i class="fa fa-check"></i><b>3.2</b> Regularity and Solvability</a></li>
<li class="chapter" data-level="3.3" data-path="III.html"><a href="III.html#solution-to-the-n-dae-regularity-and-index-of-a-matrix-pair"><i class="fa fa-check"></i><b>3.3</b> Solution to the <em>N-DAE</em>, Regularity, and Index of a Matrix Pair</a></li>
<li class="chapter" data-level="3.4" data-path="III.html"><a href="III.html#III-ex-sols"><i class="fa fa-check"></i><b>3.4</b> Existence of Solutions</a></li>
<li class="chapter" data-level="3.5" data-path="III.html"><a href="III.html#a-variation-of-constant-formula"><i class="fa fa-check"></i><b>3.5</b> A Variation of Constant Formula</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="IV.html"><a href="IV.html"><i class="fa fa-check"></i><b>4</b> Linear DAEs with Time-varying Coefficients</a><ul>
<li class="chapter" data-level="4.1" data-path="IV.html"><a href="IV.html#a-local-canonical-form"><i class="fa fa-check"></i><b>4.1</b> A Local Canonical Form</a></li>
<li class="chapter" data-level="4.2" data-path="IV.html"><a href="IV.html#IV-Global-Canonical-Form"><i class="fa fa-check"></i><b>4.2</b> A Global Canonical Form</a></li>
<li class="chapter" data-level="4.3" data-path="IV.html"><a href="IV.html#the-strangeness-index"><i class="fa fa-check"></i><b>4.3</b> The Strangeness Index</a></li>
<li class="chapter" data-level="4.4" data-path="IV.html"><a href="IV.html#derivative-arrays"><i class="fa fa-check"></i><b>4.4</b> Derivative Arrays</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="numerical-approximation-of-daes.html"><a href="numerical-approximation-of-daes.html"><i class="fa fa-check"></i><b>5</b> Numerical Approximation of DAEs</a><ul>
<li class="chapter" data-level="5.1" data-path="numerical-approximation-of-daes.html"><a href="numerical-approximation-of-daes.html#Vi"><i class="fa fa-check"></i><b>5.1</b> Notions and Notations</a></li>
<li class="chapter" data-level="5.2" data-path="numerical-approximation-of-daes.html"><a href="numerical-approximation-of-daes.html#runge-kutta-methods-for-linear-daes-with-constant-coefficients"><i class="fa fa-check"></i><b>5.2</b> Runge-Kutta Methods for Linear DAEs with Constant Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="construction-and-analysis-of-rkm-for-nonlinear-daes.html"><a href="construction-and-analysis-of-rkm-for-nonlinear-daes.html"><i class="fa fa-check"></i><b>6</b> Construction and Analysis of RKM for nonlinear DAEs</a><ul>
<li class="chapter" data-level="6.1" data-path="construction-and-analysis-of-rkm-for-nonlinear-daes.html"><a href="construction-and-analysis-of-rkm-for-nonlinear-daes.html#general-rkm-for-semi-explicit-strangeness-free-daes"><i class="fa fa-check"></i><b>6.1</b> General RKM for Semi-Explicit Strangeness-free DAEs</a></li>
<li class="chapter" data-level="6.2" data-path="construction-and-analysis-of-rkm-for-nonlinear-daes.html"><a href="construction-and-analysis-of-rkm-for-nonlinear-daes.html#collocation-rkm-for-implicit-strangeness-free-daes"><i class="fa fa-check"></i><b>6.2</b> Collocation RKM for Implicit Strangeness-free DAEs</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="examples-1.html"><a href="examples-1.html"><i class="fa fa-check"></i><b>7</b> Examples</a><ul>
<li class="chapter" data-level="7.1" data-path="examples-1.html"><a href="examples-1.html#semi-discrete-navier-stokes-equations"><i class="fa fa-check"></i><b>7.1</b> Semi-discrete Navier-Stokes equations</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>8</b> Exercises</a><ul>
<li class="chapter" data-level="8.1" data-path="exercises.html"><a href="exercises.html#ii.c.1"><i class="fa fa-check"></i><b>8.1</b> II.C.1</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="numerical-analysis-and-software-overview.html"><a href="numerical-analysis-and-software-overview.html"><i class="fa fa-check"></i><b>9</b> Numerical Analysis and Software Overview</a><ul>
<li class="chapter" data-level="9.1" data-path="numerical-analysis-and-software-overview.html"><a href="numerical-analysis-and-software-overview.html#theory-rkms-and-bdf-for-daes"><i class="fa fa-check"></i><b>9.1</b> Theory: RKMs and BDF for DAEs</a></li>
<li class="chapter" data-level="9.2" data-path="numerical-analysis-and-software-overview.html"><a href="numerical-analysis-and-software-overview.html#solvers"><i class="fa fa-check"></i><b>9.2</b> Solvers</a></li>
<li class="chapter" data-level="9.3" data-path="numerical-analysis-and-software-overview.html"><a href="numerical-analysis-and-software-overview.html#software"><i class="fa fa-check"></i><b>9.3</b> Software</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DAEs</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="IV" class="section level1">
<h1><span class="header-section-number">4</span> Linear DAEs with Time-varying Coefficients</h1>
<p>In this section, we consider linear DAEs with <em>variable</em> or <em>time-dependent</em> coefficients. This means, for matrix-valued functions
<span class="math display">\[
E \in \mathcal C(\mathcal I, \mathbb C^{m,n}), \quad A\in \mathcal C(\mathcal I, \mathbb C^{m,n})
\]</span>
and <span class="math inline">\(f\in \mathcal C(\mathcal I, \mathbb C^{m})\)</span>, we consider the DAE
<span class="math display" id="eq:iv-ltv-dae">\[\begin{equation}
E(t)\dot x(t) = A(t)x(t) + f(t) \tag{4.1}
\end{equation}\]</span>
with, possibly, an initial condition
<span class="math display" id="eq:iv-ltv-inicond">\[\begin{equation}
x(t_0) = x_0 \in \mathbb C^{n}. \tag{4.2}
\end{equation}\]</span></p>

<div class="JHSAYS">
The same <a href="basic-definitions-and-notions.html#def:dae-solution">general solution concept</a> applies. Basically <span class="math inline">\(x\)</span> should be differentiable, fulfill the DAE, and, if stated, the initial condition too.
</div>

<p>In the constant coefficient case, <a href="III.html/#def:regularity">regularity</a> played a decisive role for the existence and uniqueness of solutions; see, e.g. <a href="III.html#III-ex-sols">Section</a> <a href="III.html#III-ex-sols">3.4</a>. Thus it seems natural to extend this concept to the time-varying case, e.g., through requiring that <span class="math inline">\((E(t), A(t))\)</span> is a regular matrix pair independent of <span class="math inline">\(t\)</span>. However, the following two examples show that this will not work <em>out of the box</em>.</p>

<div class="example">
<span id="exm:ltv-regular-infinite-sols" class="example"><strong>Example 4.1  </strong></span>Let <span class="math inline">\(E\)</span>, <span class="math inline">\(A\)</span> be given as
<span class="math display">\[
E(t) = 
\begin{bmatrix}
-t &amp; t^2 \\ -1 &amp; t 
\end{bmatrix}, \quad
A(t) = 
\begin{bmatrix}
-1 &amp; 0 \\ 0&amp; -1
\end{bmatrix}
\]</span>
Then
<span class="math display">\[
\det ( \lambda E(t) - A(t)) = (1-\lambda t)(1+\lambda t) + \lambda ^2 t^2 \equiv 1,
\]</span>
for all <span class="math inline">\(t\in \mathcal I\)</span>. Still, for every <span class="math inline">\(c \in \mathcal C^1(\mathcal I, \mathbb C)\)</span> with <span class="math inline">\(c(t_0)=0\)</span>, the function
<span class="math display">\[
x\colon t \mapsto c(t)\begin{bmatrix} t\\1 \end{bmatrix}
\]</span>
solves the <em>homogeneous</em> initial value problem <a href="IV.html#eq:iv-ltv-dae">(4.1)</a>–<a href="IV.html#eq:iv-ltv-inicond">(4.2)</a>.
</div>

<div class="JHSAYS">
<p>
This was an example where the pair <span class="math inline"><span class="math inline">\((E,A)\)</span></span> is regular uniformly with respect to <span class="math inline"><span class="math inline">\(t\)</span></span> but still allows for infinitely many solutions to the associated DAE. <strong>X</strong>: What about the initial value? Why it won’t help to make the solution unique?
</p>
<p>
Next we see the contrary – a matrix pair that is singular for any <span class="math inline"><span class="math inline">\(t\)</span></span> but defines a unique solution.
</p>
</div>

<div class="example">
<span id="exm:ltv-singular-unique-sol" class="example"><strong>Example 4.2  </strong></span>For
<span class="math display">\[
E(t) = 
\begin{bmatrix}
0 &amp; 0 \\ 1 &amp; -t 
\end{bmatrix}, \quad
A(t) = 
\begin{bmatrix}
-1 &amp; t \\ 0&amp;0 
\end{bmatrix}, \quad
f(t) = 
\begin{bmatrix}
f_1(t) \\ f_2(t)
\end{bmatrix}, 
\]</span>
one has
<span class="math display">\[
\det ( \lambda E(t) - A(t)) = 0
\]</span>
for all <span class="math inline">\(t\in \mathcal I\)</span>. Still, if <span class="math inline">\(x=(x_1, x_2)\)</span> denotes the solution, from the first line of the DAE
<span class="math display">\[\begin{align*}
0 &amp;= -x_1(t) + tx_2(t) + f_1(t) \\
\dot x_1 - t\dot x_2(t) &amp;= \phantom{-x_1(t) + tx_2(t) +}f_2(t)
\end{align*}\]</span>
one can calculate directly that
<span class="math display">\[
\dot x_1(t) = t\dot x_2(t) +x_2 + \dot{f_1}(t)
\]</span>
or that
<span class="math display">\[
\dot x_1(t) - t\dot x_2(t) = x_2 + \dot{f_1}(t)
\]</span>
so that the second line becomes
<span class="math display">\[
x_2(t) +  \dot{f_1}(t) = f_2(t)
\]</span>
which uniquely defines
<span class="math display">\[
x_2(t) =  - \dot{f_1}(t) + f_2(t)
\]</span>
and also
<span class="math display">\[
x_1(t) =  - t(\dot{f_1}(t) + f_2(t))+f_1(t).
\]</span>
</div>

<div class="JHSAYS">
<p>
For both examples one can then simply choose <span class="math inline"><span class="math inline">\(x(t_0)\)</span></span> in accordance with the right hand side to argue about whether and how a solution exists.
</p>
</div>
<p>Recall that for the <em>constant coefficient</em> case, we were using invertible scaling and state transformation matrices <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> for the equivalence transformations
<span class="math display">\[
E \dot x(t) = Ax(t) +f(t) \quad \sim \quad \tilde E \dot {\tilde x(t)} = \tilde A\tilde x(t) +\tilde f(t) 
\]</span></p>
<p>with</p>
<p><span class="math display">\[
x=Q\tilde x, \quad \tilde E = PEQ, \quad \tilde A = PAQ, \quad \tilde f = Pf.
\]</span></p>
<p>For the time-varying case, we will use time-varying transformations and require that they are invertible at every point <span class="math inline">\(t\)</span> in time.</p>

<div class="definition">
<span id="def:global-equivalence" class="definition"><strong>Definition 4.1  </strong></span>Two pairs <span class="math inline">\((E_i,A_i)\)</span>, <span class="math inline">\(E_i\)</span>, <span class="math inline">\(A_i \in \mathcal C(\mathcal I, \mathbb C^{m,n})\)</span>,
<span class="math inline">\(i=1,2\)</span>, of matrix functions are called <em>(globally) equivalent</em>, if there exist
pointwise nonsingular matrix functions <span class="math inline">\(P\in \mathcal C(\mathcal I, \mathbb C^{m,m})\)</span> and <span class="math inline">\(Q\in \mathcal C^1(\mathcal I, \mathbb C^{n,n})\)</span> such that
<span class="math display" id="eq:iv-glob-equiv-mpairs">\[\begin{equation}
E_2=PE_1Q, \quad A_2 = PA_1Q-PE_1\dot Q \tag{4.3}
\end{equation}\]</span>
for all <span class="math inline">\(t\in \mathcal I\)</span>. Again, we write <span class="math inline">\((E_1,A_1) \sim (E_2, A_2)\)</span>.
</div>

<div class="JHSAYS">
<p>
The need of <span class="math inline"><span class="math inline">\(Q\)</span></span> being differentiable and the appearance of <span class="math inline"><span class="math inline">\(E_1\dot Q\)</span></span> in the definition of <span class="math inline"><span class="math inline">\(A_2\)</span></span> comes from the relation <span class="math display"><span class="math display">\[
E\dot x(t) = E\frac{d}{dt} (Q\tilde x)(t) = E\bigl(Q(t)\dot {\tilde x}(t) + \dot Q(t)\tilde x(t) \bigr)
\]</span></span> for the transformed state <span class="math inline"><span class="math inline">\(\tilde x\)</span></span> with the actual state <span class="math inline"><span class="math inline">\(x\)</span></span>.
</p>
</div>

<div class="lemma">
<span id="lem:iv-glob-equiv-rst" class="lemma"><strong>Lemma 4.1  </strong></span>The relation on pairs of matrix functions as defined in Definition <a href="IV.html#def:global-equivalence">4.1</a> is an equivalence relation.
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> Exercise!
</div>

<p>Next we will define <em>local</em> equivalence of matrix pairs.</p>

<div class="definition">
<span id="def:local-equivalence" class="definition"><strong>Definition 4.2  </strong></span>Two pairs <span class="math inline">\((E_i,A_i)\)</span>, <span class="math inline">\(E_i\)</span>, <span class="math inline">\(A_i \in \mathbb C^{m,n}\)</span>,
<span class="math inline">\(i=1,2\)</span>, of matrices are called <em>locally equivalent</em>, if there exist
pointwise nonsingular matrices <span class="math inline">\(P \in \mathbb C^{m,m})\)</span> and <span class="math inline">\(Q\in \mathbb C^{n,n}\)</span> such that as well as matrix <span class="math inline">\(R\in \mathbb C^{n,n}\)</span> such that
<span class="math display" id="eq:iv-loc-equiv-mpairs">\[\begin{equation}
E_2=PE_1Q, \quad A_2 = PA_1Q-PE_1R \tag{4.4}.
\end{equation}\]</span>
Again, we write <span class="math inline">\((E_1,A_1) \sim (E_2, A_2)\)</span> and differentiate by context.
</div>


<div class="lemma">
<span id="lem:iv-loc-equiv-rst" class="lemma"><strong>Lemma 4.2  </strong></span>The local equivalence as defined in Definition <a href="IV.html#def:local-equivalence">4.2</a> is an equivalence relation on pairs of matrices.
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> Exercise!
</div>

<p>We state a few observations:</p>
<ul>
<li>Global equivalence implies local equivalence at all points of time <span class="math inline">\(t\)</span>.</li>
<li>Vice versa, pointwise local equivalence, e.g. at some time instances <span class="math inline">\(t_i\)</span> with suitable matrices <span class="math inline">\(P_i\)</span>, <span class="math inline">\(Q_i\)</span>, <span class="math inline">\(R_i\)</span>, can be interpolated to a continuous matrix function <span class="math inline">\(P\)</span> and a differentiable matrix function <span class="math inline">\(Q\)</span> by <em>Hermite interpolation</em>, i.e. via
<span class="math display">\[
P(t_i) = P_i, \quad Q(t_i) = Q_i, \quad \dot Q(t_i) = R_i.
\]</span></li>
<li>Local equivalence is more powerful than the simple equivalence of matrix pairs (cp. Definition <a href="III.html#def:matrix-pair-equivalent">3.1</a>) for which <span class="math inline">\(R=0\)</span>. This means we can expect more structure in a normal form.</li>
</ul>
<div id="a-local-canonical-form" class="section level2">
<h2><span class="header-section-number">4.1</span> A Local Canonical Form</h2>
<p>For easier explanations, we introduce the slightly incorrect wording that a <em>matrix</em> <span class="math inline">\(M\)</span> <em>spans</em> a vector space <span class="math inline">\(V\)</span> to express that the <span class="math inline">\(V\)</span> is the span of the columns of <span class="math inline">\(V\)</span>. Similarly, we will say that <span class="math inline">\(M\)</span> <em>is a basis of</em> <span class="math inline">\(V\)</span>, if the columns of <span class="math inline">\(M\)</span> form a basis for <span class="math inline">\(V\)</span>.</p>
<p>Some more notation:</p>
<table>
<colgroup>
<col width="42%" />
<col width="57%" />
</colgroup>
<thead>
<tr class="header">
<th>Notation</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(V^H\in \mathbb C^{n,m}\)</span></td>
<td>the <a href="https://en.wikipedia.org/wiki/Conjugate_transpose"><em>conjugate transpose</em> or <em>Hermitian transpose</em></a> of a matrix <span class="math inline">\(V\in \mathbb C^{m,n}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(T&#39; \in \mathbb C^{n,n-k}\)</span></td>
<td>The <em>complementary space</em> as a matrix. If <span class="math inline">\(T\in \mathbb C^{n,k}\)</span> is a basis of <span class="math inline">\(V\)</span>, then <span class="math inline">\(T&#39;\)</span> contains a basis of <span class="math inline">\(V&#39;\)</span> so that <span class="math inline">\(V\oplus V&#39; = \mathbb C^{n}\)</span>. In particular, the matrix <span class="math inline">\(\begin{bmatrix}T&amp;T&#39;\end{bmatrix}\)</span> is square and invertible.</td>
</tr>
</tbody>
</table>

<div class="theorem">
<p><span id="thm:local-canonical-form" class="theorem"><strong>Theorem 4.1  </strong></span>Let <span class="math inline">\(E, A \in \mathbb C^{m,n}\)</span> and let
<span class="math display" id="eq:lcf-subspaces">\[\begin{equation}
T,~Z,~T&#39;,~V \tag{4.5}
\end{equation}\]</span>
be</p>
<table>
<thead>
<tr class="header">
<th align="left">Matrix</th>
<th align="left">as the basis of</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(T\)</span></td>
<td align="left"><span class="math inline">\(\operatorname{kernel}E\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(Z\)</span></td>
<td align="left"><span class="math inline">\(\operatorname{corange}E = \operatorname{kernel}E^H\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(T&#39;\)</span></td>
<td align="left"><span class="math inline">\(\operatorname{cokernel}E = \operatorname{range}E^H\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(V\)</span></td>
<td align="left"><span class="math inline">\(\operatorname{corange}(Z^HAT)\)</span></td>
</tr>
</tbody>
</table>
<p>then the quantities
<span class="math display" id="eq:lcf-quantities">\[\begin{equation}
r,~a,~s,~d,~u,~v \tag{4.6}
\end{equation}\]</span>
defined as</p>
<table>
<thead>
<tr class="header">
<th align="left">Quantity</th>
<th align="left">Definition</th>
<th align="left">Name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(r\)</span></td>
<td align="left"><span class="math inline">\(\operatorname{rank}E\)</span></td>
<td align="left"><em>rank</em></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(a\)</span></td>
<td align="left"><span class="math inline">\(\operatorname{rank}(Z^HAT)\)</span></td>
<td align="left"><em>algebraic part</em></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(s\)</span></td>
<td align="left"><span class="math inline">\(\operatorname{rank}(V^HZ^HAT&#39;)\)</span></td>
<td align="left"><em>strangeness</em></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(d\)</span></td>
<td align="left"><span class="math inline">\(r-s\)</span></td>
<td align="left"><em>differential part</em></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(u\)</span></td>
<td align="left"><span class="math inline">\(n-r-a\)</span></td>
<td align="left"><em>undetermined variables</em></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(v\)</span></td>
<td align="left"><span class="math inline">\(m-r-a-s\)</span></td>
<td align="left"><em>vanishing equations</em></td>
</tr>
</tbody>
</table>
<p>are invariant under local equivalence transformations and <span class="math inline">\((E, A)\)</span> is locally equivalent to the canonical form</p>
<span class="math display" id="eq:local-canonical-form">\[\begin{equation}
\left(\begin{bmatrix}
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; I_d &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
0 &amp; 0 &amp; 0 &amp; 0  \\
0 &amp; 0 &amp; 0 &amp; 0  \\
0 &amp; 0 &amp; I_a &amp; 0 \\
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}\right),
\tag{4.7}
\end{equation}\]</span>
where all diagonal blocks are square, except maybe the last one.
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> To be provided. Until then, see Theorem 3.7 in Kunkel/Mehrmann.
</div>

<p>Some remarks on the spaces and how the names are derived for the case <span class="math inline">\(E\dot x = Ax +f\)</span> with constant coefficients. The ideas are readily transferred to the case with time-varying coefficients.</p>
<p>Let
<span class="math display">\[x(t) = Ty(t) + T&#39;y&#39;(t),\]</span></p>
<p>where <span class="math inline">\(y\)</span> denotes the components of <span class="math inline">\(x\)</span> that evolve in the range of <span class="math inline">\(T\)</span> and <span class="math inline">\(y&#39;\)</span> the respective complement. (Since <span class="math inline">\([T|T&#39;]\)</span> is a basis of <span class="math inline">\(\mathbb C^{n}\)</span>, there exist such <span class="math inline">\(y\)</span> and <span class="math inline">\(y&#39;\)</span> that uniquely define <span class="math inline">\(x\)</span> and vice versa). With <span class="math inline">\(T\)</span> spanning <span class="math inline">\(\ker E\)</span> we find that</p>
<p><span class="math display">\[
E \dot x(t) = ET\dot y(t) + ET&#39;\dot y&#39;(t) = ET&#39;\dot y&#39;(t)
\]</span></p>
<p>so that the DAE basically reads</p>
<p><span class="math display">\[ET&#39;\dot y&#39;(t) = ATy(t) + AT&#39;y&#39;(t)+f,\]</span></p>
<p>i.e. the components of <span class="math inline">\(x\)</span> defined through <span class="math inline">\(y\)</span> are, effectively, not differentiated. With <span class="math inline">\(Z\)</span> containing exactly those <span class="math inline">\(v\)</span>, for which <span class="math inline">\(v^HE=0\)</span>, it follows that</p>
<p><span class="math display">\[Z^HET&#39;\dot y&#39;(t) = 0 = Z^HATy(t) + Z^HAT&#39;y&#39;(t)+Z^Hf,\]</span></p>
<p>or</p>
<p><span class="math display">\[Z^HATy(t) = -Z^HAT&#39;y&#39;(t)-Z^Hf,\]</span></p>
<p>so that <span class="math inline">\(\operatorname{rank}Z^HAT\)</span> indeed describes the number of purely algebraic equations and variables in the sense that it defines parts of <span class="math inline">\(y\)</span> (which is never going to be differentiated) in terms of algebraic relations (no time derivatives are involved).</p>
<p>With the same arguments and with <span class="math inline">\(V=\operatorname{corange}Z^HAT\)</span>, it follows that</p>
<p><span class="math display">\[V^HZ^HAT&#39;y&#39;(t) = -V^HZ^HATy(t) -V^HZ^Hf=-V^HZ^Hf,\]</span></p>
<p>is the part of <span class="math inline">\(E\dot x = Ax + f\)</span> in which those components <span class="math inline">\(y&#39;\)</span> that are also differentiated are algebraically equated to a right-hand side. This is the <em>strangeness</em> (rather in the sense of <em>skewness</em>) of DAEs that variables can be both differential and algebraic. Accordingly, <span class="math inline">\(\operatorname{rank}V^HZ^HAT&#39;\)</span> describes the size of the skewness component.</p>
<p>Finally, those variables that are neither <em>strange</em> nor purely algebraic, i.e. those that are differentiated but not defined algebraically, are the <em>differential</em> variables. There is no direct characterization of them, but one can calculate their number as <span class="math inline">\(r-s\)</span>, which means number of differentiated minus number of <em>strange</em> variables.</p>
<div class="JHSAYS">
<p>
<strong>Outlook</strong>: If there is no strangeness, the DAE is called strangeness-free. Strangeness can be eliminated through iterated differentiation and substitution. The needed number of such iterations (that is independent of the the size <span class="math inline"><span class="math inline">\(s\)</span></span> of the <em>strange</em> block here) will define the strangeness index.
</p>
</div>

<div class="example">
<p><span id="exm:strangeness-in-the-circuit" class="example"><strong>Example 4.3  </strong></span>With a basic state transformation
<span class="math display">\[
\begin{bmatrix}
\tilde x_1 \\ \tilde x_2 \\ \tilde x_3
\end{bmatrix}
= 
\begin{bmatrix}
x_3 - x_2 \\ x_2-x_1 \\ x_3
\end{bmatrix},
\]</span>
one finds for the coefficients of Example <a href="introduction.html#exm:the-circuit">1.2</a> that:
<span class="math display">\[
(E, A) \backsim 
\left(
\begin{bmatrix} C &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp;0 \\ 0 &amp; 0 &amp;0  \end{bmatrix}
,
\begin{bmatrix} 0 &amp; \frac{1}{R} &amp; 0 \\ -1 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{bmatrix}
\right).
\]</span></p>
<p>We compute the subspaces as defined in <a href="IV.html#eq:lcf-subspaces">(4.5)</a>:</p>
<table>
<colgroup>
<col width="30%" />
<col width="69%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Matrix</th>
<th align="left">as the basis of/computed as</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(T=\begin{bmatrix} 0 \\ I_2 \end{bmatrix}\)</span></td>
<td align="left"><span class="math inline">\(\operatorname{kernel}\begin{bmatrix} C &amp; 0 \\ 0 &amp; 0_2 \end{bmatrix}\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(Z=\begin{bmatrix} 0 \\ I_2 \end{bmatrix}\)</span></td>
<td align="left"><span class="math inline">\(\operatorname{corange}\begin{bmatrix} C &amp; 0 \\ 0 &amp; 0_2 \end{bmatrix}=\operatorname{kernel}\begin{bmatrix} C &amp; 0 \\ 0 &amp; 0_2 \end{bmatrix}^H\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(T&#39;=\begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}\)</span></td>
<td align="left"><span class="math inline">\(\operatorname{cokernel}\begin{bmatrix} C &amp; 0 \\ 0 &amp; 0_2 \end{bmatrix}=\operatorname{range}\begin{bmatrix} C &amp; 0 \\ 0 &amp; 0_2 \end{bmatrix}^H\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(Z^HAT=I_2\)</span></td>
<td align="left"><span class="math inline">\(\begin{bmatrix} 0 \\ I_2 \end{bmatrix}^H\begin{bmatrix} 0 &amp; \frac{1}{R} &amp; 0 \\ -1 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{bmatrix}\begin{bmatrix} 0 \\ I_2 \end{bmatrix}\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(V=\begin{bmatrix} 0 \\ 0 \end{bmatrix}\)</span></td>
<td align="left"><span class="math inline">\(\operatorname{corange}(Z^HAT) = \operatorname{kernel}I_2^H\phantom{\begin{bmatrix} 0 \\ I_1 \end{bmatrix}}\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(V^HZ^HAT&#39;=\begin{bmatrix} 0 \end{bmatrix}\)</span></td>
<td align="left"><span class="math inline">\(\begin{bmatrix} 0 \\ 0 \end{bmatrix}^H\begin{bmatrix} 0 \\ I_2 \end{bmatrix}^H\begin{bmatrix} 0 &amp; \frac{1}{R} &amp; 0 \\ -1 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{bmatrix}\begin{bmatrix} 1 \\0 \\ 0 \end{bmatrix}\)</span></td>
</tr>
</tbody>
</table>
<p>and derive the quantities as defined in <a href="IV.html#eq:lcf-quantities">(4.6)</a>:</p>
<table>
<colgroup>
<col width="22%" />
<col width="25%" />
<col width="51%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Name</th>
<th align="left">Value</th>
<th>Derived from</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">rank</td>
<td align="left"><span class="math inline">\(r=1\)</span></td>
<td><span class="math inline">\(\operatorname{rank}E = \operatorname{rank}\begin{bmatrix} C &amp; 0 \\ 0 &amp; 0_2 \end{bmatrix}\)</span></td>
</tr>
<tr class="even">
<td align="left">algebraic part</td>
<td align="left"><span class="math inline">\(a=2\)</span></td>
<td><span class="math inline">\(\operatorname{rank}Z^HAT = \operatorname{rank}I_2\)</span></td>
</tr>
<tr class="odd">
<td align="left">strangeness</td>
<td align="left"><span class="math inline">\(s=0\)</span></td>
<td><span class="math inline">\(\operatorname{rank}V^HZ^HAT&#39; = \operatorname{rank}\begin{bmatrix} 0\end{bmatrix}\)</span></td>
</tr>
<tr class="even">
<td align="left">differential part</td>
<td align="left"><span class="math inline">\(d=1\)</span></td>
<td><span class="math inline">\(d=r-s=1-0\)</span></td>
</tr>
<tr class="odd">
<td align="left">undetermined variables</td>
<td align="left"><span class="math inline">\(u=0\)</span></td>
<td><span class="math inline">\(u=n-r-a=3-2-1\)</span></td>
</tr>
<tr class="even">
<td align="left">vanishing equations</td>
<td align="left"><span class="math inline">\(v=0\)</span></td>
<td><span class="math inline">\(v=m-r-a-s=3-2-1-0\)</span></td>
</tr>
</tbody>
</table>
</div>


<div class="example">
<span id="exm:strangeness-in-the-nse" class="example"><strong>Example 4.4  </strong></span>
</div>

<div class="JHSAYS">
<p>
For the semi-discrete linearized Navier-Stokes equations, the derivation of the <em>local characteristic quantities</em> is laid out in the <a href="examples-1.html#x-nse-local-char-vals">Example Section</a>.
</p>
</div>
<p>```</p>
</div>
<div id="IV-Global-Canonical-Form" class="section level2">
<h2><span class="header-section-number">4.2</span> A Global Canonical Form</h2>
<p>A few observations:</p>
<ul>
<li>For a pair of <span class="math inline">\((E, A)\)</span> of <strong>matrix functions</strong>, we can compute the characteristic values <span class="math inline">\(r\)</span>, <span class="math inline">\(a\)</span>, <span class="math inline">\(s\)</span>, <span class="math inline">\(d\)</span> as in <a href="IV.html#eq:lcf-quantities">(4.6)</a> for any given <span class="math inline">\(t\in \mathcal I\)</span>.</li>
<li>Thus, <span class="math inline">\(r\)</span>, <span class="math inline">\(a\)</span>, <span class="math inline">\(s\)</span>, <span class="math inline">\(d\colon \mathcal I \to \mathbb R\)</span> are functions of time <span class="math inline">\(t\)</span>.</li>
<li>We will assume that <span class="math inline">\(r\)</span>, <span class="math inline">\(a\)</span>, <span class="math inline">\(s\)</span>, <span class="math inline">\(d\)</span> are constant in time:
<ul>
<li>Analysis will be enabled through a so-called smooth singular value decomposition (SVD – see the following theorem) that applies for matrices of constant rank.</li>
<li>Smooth matrix functions have countably many jumps in the rank. The analysis can be performed on subintervals, where the rank of the matrices are constant.</li>
<li>In practice, typically, there are but a few jumps in the rank at somewhat particular but known time instances or circumstances.</li>
</ul></li>
</ul>
<div class="JHSAYS">
<p>
About a few and known jumps in the rank: A change in the ranks means an instantaneous change in the model itself. In fact the characteristic values, like the number of purely algebraic equations, would change suddenly. An example is the activation of a switch in an electrical circuit or <em>switched systems</em> in general.
</p>
</div>

<div class="theorem">
<p><span id="thm:continuous-svd" class="theorem"><strong>Theorem 4.2  (see Kunkel/Mehrmann, Thm. 3.9)  </strong></span>
Let <span class="math inline">\(E\in \mathcal C^\ell(I, \mathbb C^{m,n})\)</span> with <span class="math inline">\(\operatorname{rank}E(t)=r\)</span> for all <span class="math inline">\(t\in I\)</span>. Then there exist pointwise unitary (and, thus, nonsingular) matrix functions <span class="math inline">\(U\in \mathcal C^\ell(I, \mathbb C^{m,m})\)</span> and <span class="math inline">\(V\in \mathcal C^\ell(I, \mathbb C^{n,n})\)</span>, such that</p>
<span class="math display">\[
 U^HEV =
 \begin{bmatrix}
 \Sigma &amp; 0 \\
 0 &amp; 0
 \end{bmatrix}
\]</span>
with pointwise nonsingular <span class="math inline">\(\Sigma \in \mathcal C^l(I, \mathbb C^{r,r})\)</span>.
</div>


<div class="theorem">
<p><span id="thm:global-canonical-form" class="theorem"><strong>Theorem 4.3  </strong></span>
Let <span class="math inline">\(E, A \in \mathcal C^l(I, \mathbb C^{m,n})\)</span> be sufficiently smooth and suppose that
<span class="math display" id="eq:glob-local-char-vals">\[\begin{equation}
    r(t) = r, \quad a(t)=a, \quad s(t)=s \tag{4.8}
\end{equation}\]</span></p>
<p>for the local characteristic values of <span class="math inline">\((E(t), A(t))\)</span>. Then <span class="math inline">\((E, A)\)</span> is globally equivalent to the canonical form
<span class="math display" id="eq:iv-glob-can-form">\[\begin{equation}
\left(
\begin{bmatrix}
I_s &amp;  0  &amp; 0 &amp; 0 \\
0   &amp; I_d &amp; 0 &amp; 0 \\
0   &amp;  0  &amp; 0 &amp; 0 \\
0   &amp;  0  &amp; 0 &amp; 0 \\
0   &amp;  0  &amp; 0 &amp; 0
\end{bmatrix}, 
\begin{bmatrix}
0   &amp; A_{12}&amp;  0  &amp; A_{14} \\
0   &amp;   0   &amp;  0  &amp; A_{24} \\
0   &amp;   0   &amp; I_a &amp; 0 \\
I_s &amp;   0   &amp;  0  &amp; 0 \\
0   &amp;   0   &amp;  0  &amp; 0
\end{bmatrix}
\right ).
\tag{4.9}
\end{equation}\]</span></p>
<p>All entries are again matrix functions on <span class="math inline">\(I\)</span> and the last block column in both matrix functions of <a href="IV.html#eq:iv-glob-can-form">(4.9)</a> has size <span class="math inline">\(u=n-s-d-a\)</span>.</p>
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> In what follows, we will tacitly redefine the block matrix entries that appear after the global equivalence transformations. The first step is the continous SVD of <span class="math inline">\(E\)</span>; see Theorem <a href="IV.html#thm:global-canonical-form">4.3</a>. In what follows, the basic operations of</p>
<ul>
<li>condensing blocks by the continuous SVD, e.g. <span class="math inline">\(U_2^HA_{31}V_2=\begin{bmatrix} I_s &amp; 0 \\ 0 &amp; 0 \end{bmatrix}\)</span></li>
<li>and eliminating blocks through by adding multiples of columns or rows</li>
</ul>
<p>are applied repeatedly:</p>
<!-- \begin{ofalltheseblockmats} -->
<span class="math display">\[\begin{align*}
(E,A) &amp; 
\sim   
\left(\begin{bmatrix}
\Sigma &amp; 0 \\
0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
A_{11} &amp; A_{12} \\
A_{21} &amp; A_{22}
\end{bmatrix}\right) \\
%%%%%%%%%%%%%%%%%%%%%%%%%%
&amp; \sim   
\left(\begin{bmatrix}
I_r &amp; 0 \\
0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
A_{11} &amp; A_{12} \\
A_{21} &amp; A_{22}
\end{bmatrix}\right) \\
%%%%%%%%%%%%%%%%%%%%%%
&amp; \sim   
\left(\begin{bmatrix}
I_r &amp; 0 \\
0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
A_{11} &amp; A_{12}V_1 \\
U_1^HA_{21} &amp; U_1^HA_{22}V_1 
\end{bmatrix} -
\begin{bmatrix} I_r &amp; 0 \\ 0 &amp; 0 \end{bmatrix}
\begin{bmatrix} 0 &amp; 0 \\ 0 &amp; \dot V_1 \end{bmatrix}
\right) \\
%%%%%%%%%%%%%%%%%%%%%%
&amp; \sim   
\left(\begin{bmatrix}
I_r &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
A_{11} &amp; A_{12} &amp; A_{13}\\
A_{21} &amp; I_a &amp; 0 \\
A_{31} &amp; 0  &amp; 0
\end{bmatrix}\right) \\
%%%%%%%%%%%%%%%%%%%%%%
&amp; \sim   
\left(\begin{bmatrix}
V_2 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
A_{11}V_2 &amp; A_{12} &amp; A_{13}\\
A_{21}V_2 &amp; I_a &amp; 0 \\
U_2^HA_{31}V_2 &amp; 0 &amp; 0
\end{bmatrix} -
\begin{bmatrix}
\dot I_r &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{bmatrix}
\begin{bmatrix}
\dot V_2 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{bmatrix} \right)\\
%%%%%%%%%%%%%%%%%%%%%%
&amp; \sim   
\left(\begin{bmatrix}
V_{11} &amp; V_{12} &amp; 0 &amp; 0 \\
V_{21} &amp; V_{22} &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
A_{11} &amp; A_{12} &amp; A_{13} &amp; A_{14}  \\
A_{21} &amp; A_{22} &amp; A_{23} &amp; A_{24}  \\
A_{31} &amp; A_{32} &amp; I_a &amp; 0 \\
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix} \right)\\
%%%%%%%%%%%%%%%%%%%%%%
&amp; \sim   
\left(\begin{bmatrix}
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; I_d &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
0 &amp; A_{12} &amp; A_{13} &amp; A_{14}  \\
0 &amp; A_{22} &amp; A_{23} &amp; A_{24}  \\
0 &amp; A_{32} &amp; I_a &amp; 0 \\
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix} 
\begin{bmatrix}
I_s &amp; 0 &amp; 0 &amp; 0  \\
0 &amp; I_d &amp; 0 &amp; 0  \\
0 &amp; -A_{32} &amp; I_a &amp; 0 \\
I_s &amp; 0 &amp; 0 &amp; I_a
\end{bmatrix} 
\right) \\
%%%%%%%%%%%%%%%%%
&amp; \sim   
\left(\begin{bmatrix}
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; I_d &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
0 &amp; A_{12} &amp; A_{13} &amp; A_{14}  \\
0 &amp; A_{22} &amp; A_{23} &amp; A_{24}  \\
0 &amp; 0 &amp; I_a &amp; 0 \\
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}\right)\\
%%%%%%%%%%%%%%%%%
&amp; \sim   
\left(\begin{bmatrix}
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; I_d &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
0 &amp; A_{12} &amp; 0 &amp; A_{14}  \\
0 &amp; A_{22} &amp; 0 &amp; A_{24}  \\
0 &amp; 0 &amp; I_a &amp; 0 \\
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}\right)\\
%%%%%%%%%%%%%%%%%
&amp; \sim   
\left(\begin{bmatrix}
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; Q_2 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
0 &amp; A_{12}Q_2 &amp; 0 &amp; A_{14}  \\
0 &amp; A_{22}Q_2-\dot Q_2 &amp; 0 &amp; A_{24}  \\
0 &amp; 0 &amp; I_a &amp; 0 \\
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}\right) \\
%%%%%%%%%%%%%%%%%
&amp; \sim   
\left(\begin{bmatrix}
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; I_d &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix},
\begin{bmatrix}
0 &amp; A_{12} &amp; 0 &amp; A_{14}  \\
0 &amp; 0 &amp; 0 &amp; A_{24}  \\
0 &amp; 0 &amp; I_a &amp; 0 \\
I_s &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}\right),
\end{align*}\]</span>
<!-- \end{ofalltheseblockmats} -->
where the final equivalence holds, if <span class="math inline">\(Q_2\)</span> is chosen as the (unique and pointwise invertible) solution of the linear matrix valued ODE
<span class="math display">\[
\dot Q_2 = A_{22}(t)Q_2 ,  \quad Q_2 (t_0 ) = I_d.
\]</span>
Then, the prefinal <span class="math inline">\(A_{22}\)</span>-block vanishes because of the special choice of <span class="math inline">\(Q_2\)</span> and <span class="math inline">\(E_{22}\)</span> becomes <span class="math inline">\(I_d\)</span> after scaling the second block line by <span class="math inline">\(Q_2^{-1}\)</span>.
</div>

<p>If we write down the transformed DAE that corresponds to the canonical form <a href="IV.html#eq:iv-glob-can-form">(4.9)</a>, i.e.
<span class="math display" id="eq:iv-gcf-spart-2" id="eq:iv-gcf-dpart" id="eq:iv-gcf-spart-1">\[\begin{align}
\dot x_1 &amp;= A_{12}(t)x_2 + A_{14}x_4 + f_1(t) \tag{4.10} \\
\dot x_2 &amp;= A_{24}(t)x_4 + f_2(t) \tag{4.11}\\
0 &amp;= x_3 + f_3(t) \\
0 &amp;= x_1 + f_4(t) \tag{4.12} \\
0 &amp;= f_5(t) 
\end{align}\]</span>
we can read off a few properties:</p>
<ol style="list-style-type: decimal">
<li>the part <span class="math inline">\(x_4\)</span> is <em>free to choose</em>, i.e. the undetermined part</li>
<li>the equation <span class="math inline">\(f_5=0\)</span> does not define any variable, i.e. it is the vanishing or redundant part</li>
<li>the part <span class="math inline">\(x_2\)</span> is defined through an ODE (in this representation)</li>
<li><strong>however</strong>, the part <span class="math inline">\(x_1\)</span> is <em>strange</em> (both differential and algebraic) and still linked to <span class="math inline">\(x_2\)</span>.</li>
</ol>

<div class="corollary">
<span id="cor:iv-diff-elim" class="corollary"><strong>Corollary 4.1  </strong></span>In fact, one may <strong>differentiate</strong> <a href="IV.html#eq:iv-gcf-spart-2">(4.12)</a> and <strong>eliminate</strong> <span class="math inline">\(\dot x_1\)</span> in <a href="IV.html#eq:iv-gcf-spart-1">(4.10)</a> to obtain
<span class="math display">\[
-\dot f_4 = A_{12}(t)x_2 + A_{14}x_4 + f_1(t)
\]</span>
which together with <a href="IV.html#eq:iv-gcf-dpart">(4.11)</a> becomes a new DAE for <span class="math inline">\(x_2\)</span>:
<span class="math display">\[
\bar E(t) \dot x_2 = \bar A(t) x_2 + \bar f(t)
\]</span>
with
<span class="math display" id="eq:iv-gcf-post-diff">\[\begin{equation}
\bar E(t) = 
\begin{bmatrix}
I_{d_0} \\ 0_{s_0, d_0} 
\end{bmatrix}\in \mathbb C^{d_0+s_0, d_0}, \quad
\bar A(t) =
\begin{bmatrix}
0_{d_0} \\ A_{12}(t)
\end{bmatrix} \in \mathbb C^{d_0+s_0, d_0}, \quad \tag{4.13}
\end{equation}\]</span>
and
<span class="math display">\[
\bar f(t) =
\begin{bmatrix}
A_{24}x_4(t) + f_2(t) \\ A_{14}x_4(t)+f_1(t)-\dot f_4(t)
\end{bmatrix} \in \mathbb C^{d_0+s_0}.
\]</span>
Here, we have used the subscript to note that these <span class="math inline">\(d\)</span> and <span class="math inline">\(s\)</span> quantities were characteristic for the initial matrix pair <span class="math inline">\((E, A)\)</span>. Now, after this differentiation step, one can calculate the characteristic values <span class="math inline">\(d_1\)</span>, <span class="math inline">\(a_1\)</span>, <span class="math inline">\(s_1\)</span> again for the pair <span class="math inline">\((E_1, A_1)\)</span> which is obtained from the canonical form of Theorem <a href="IV.html#eq:iv-glob-can-form">(4.9)</a> by replacing equations <a href="IV.html#eq:iv-gcf-spart-1">(4.10)</a>–<a href="IV.html#eq:iv-gcf-dpart">(4.11)</a> by the DAE with <span class="math inline">\((\bar E, \bar A)\)</span> as in <a href="IV.html#eq:iv-gcf-post-diff">(4.13)</a>.
</div>

<p>The following theorem states that this <em>differentiation-elimination</em> step
(which is <strong>not</strong> a global equivalence operation on matrix pairs) is well-defined in the sense that the <em>next iteration</em> characteristic values are invariant under global equivalence transformations.</p>

<div class="theorem">
<span id="thm:iv-diff-elim-invariant" class="theorem"><strong>Theorem 4.4  </strong></span>Assume that the pairs <span class="math inline">\((E, A)\)</span> and <span class="math inline">\((\tilde E, \tilde A)\)</span> are globally equivalent and in the global canonical form <a href="IV.html#eq:iv-glob-can-form">(4.9)</a>. Then the pairs <span class="math inline">\((E_1, A_1)\)</span> and <span class="math inline">\((\tilde E_1, \tilde A_1)\)</span> that are obtained by differentiation and elimination as described in Corollary <a href="IV.html#cor:iv-diff-elim">4.1</a> are globally equivalent too.
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> See Kunkel/Mehrmann: Theorem 3.14.
</div>

</div>
<div id="the-strangeness-index" class="section level2">
<h2><span class="header-section-number">4.3</span> The Strangeness Index</h2>
<p>Theorem <a href="IV.html#thm:iv-diff-elim-invariant">4.4</a> comes with a number of implications:</p>
<ul>
<li>Starting with <span class="math inline">\((E, A):=(E_0, A_0)\)</span>, we can define <span class="math inline">\((E_i, A_i)\)</span>, <span class="math inline">\(i \in \mathbb N \cup {0}\)</span> as follows
<ol style="list-style-type: decimal">
<li><span class="math inline">\((E_i, A_i)\)</span> is the global canonical form</li>
<li>differentiate and eliminate as in Corollary <a href="IV.html#cor:iv-diff-elim">4.1</a> and bring the obtained pair into global canonical form to obtain <span class="math inline">\((E_{i+1}, A_{i+1})\)</span>.</li>
</ol></li>
<li>this gives a series of invariants <span class="math inline">\((r_i, a_i, s_i)\)</span> – invariant under global equivalence transforms –</li>
<li>Since <span class="math inline">\(r_{i+1} = r_i - s_i\)</span> and <span class="math inline">\(r_i \geq 0\)</span> (rank of a matrix is always greater than zero) there exists a <span class="math inline">\(\mu \in \mathbb N \cup \{0\}\)</span> for which <span class="math inline">\(s_\mu = 0\)</span>.</li>
<li>This <span class="math inline">\(\mu\)</span> is also characteristic for a matrix pair (because <span class="math inline">\(r_i\)</span> and <span class="math inline">\(s_i\)</span> are).</li>
</ul>
<p>With these observations, the following definition is well-posed.</p>

<div class="definition">
<p><span id="def:iv-strangeness-index" class="definition"><strong>Definition 4.3  </strong></span>Let <span class="math inline">\((E,A)\)</span> be a pair of sufficiently smooth matrix functions and let the sequence <span class="math inline">\((r_i, a_i, s_i)\)</span>, <span class="math inline">\(i=0,1,2,3,...\)</span>, of global characteristic values for the pairs <span class="math inline">\((E_i, A_i)\)</span> that are generated as</p>
<ul>
<li><span class="math inline">\((E_0, A_0):= (E, A)\)</span></li>
<li><span class="math inline">\((E_{i+1}, A_{i+1})\)</span> is derived from bringing <span class="math inline">\((E_i, A_i)\)</span> into the global canonical form as in Theorem <a href="IV.html#thm:global-canonical-form">4.3</a> and removing the <span class="math inline">\(I_s\)</span> block in <span class="math inline">\(E_{i+1}\)</span> through differentiation and elimination as in Corollary <a href="IV.html#cor:iv-diff-elim">4.1</a></li>
</ul>
be well-defined. Then, the quantity
<span class="math display">\[
\mu := \min\{i\in \mathbb N_0 | s_i=0\}
\]</span>
is called the <em>strangeness index</em> of the DAE <a href="IV.html#eq:iv-ltv-dae">(4.1)</a>. If <span class="math inline">\(\mu=0\)</span>, then the DAE is called <em>strangeness-free</em>.
</div>

<p>The practical implications of the strangeness index and the procedure of its derivation are laid out in the following theorem.</p>

<div class="theorem">
<span id="thm:iv-strangeness-free-equiv-system" class="theorem"><strong>Theorem 4.5  </strong></span>Let the strangeness index <span class="math inline">\(\mu\)</span> of <span class="math inline">\((E, A)\)</span> be well defined let <span class="math inline">\(f\in \mathcal C^\mu(\mathcal I, \mathbb C^{m})\)</span>. Then the DAE <a href="IV.html#eq:iv-ltv-dae">(4.1)</a> is equivalent (in the sense that the solution sets are in a one-to-one correspondence via a pointwise nonsingular matrix function) to a DAE of the form
<span class="math display" id="eq:iv-snf-equi-sys-vpart" id="eq:iv-snf-equi-sys-apart" id="eq:iv-snf-equi-sys-dpart">\[\begin{align}
\dot x_1(t) &amp;= A_{13}(t)x_3(t) + f_1(t) \tag{4.14}\\
0 &amp;= x_2(t) + f_2(t) \tag{4.15}\\
0 &amp;= f_3(t), \tag{4.16}
\end{align}\]</span>
where <span class="math inline">\(A_{13} \in \mathcal C(\mathcal I, \mathbb C^{d_\mu, u_\mu}\)</span> and where <span class="math inline">\(f_1\)</span>, <span class="math inline">\(f_2\)</span>, <span class="math inline">\(f_3\)</span> are defined through <span class="math inline">\(f\)</span>, <span class="math inline">\(\dot f\)</span>, , <span class="math inline">\(f^{(\mu)}\)</span>.
</div>


<div class="JHSAYS">
System <a href="IV.html#eq:iv-snf-equi-sys-dpart">(4.14)</a>–<a href="IV.html#eq:iv-snf-equi-sys-vpart">(4.16)</a> is in the form of <a href="IV.html#eq:iv-glob-can-form">(4.9)</a> with the <span class="math inline">\(I_s\)</span> blocks not present and the remaining parts of the variables, coefficients, and right hand side renumbered accordingly.
</div>


<div class="corollary">
<p><span id="cor:iv-snf-solvability" class="corollary"><strong>Corollary 4.2  </strong></span>Let the strangeness index <span class="math inline">\(\mu\)</span> of <span class="math inline">\((E, A)\)</span> be well defined let <span class="math inline">\(f\in \mathcal C^\mu(\mathcal I, \mathbb C^{m})\)</span>. Then</p>
<ol style="list-style-type: decimal">
<li><p>The DAE <a href="IV.html#eq:iv-ltv-dae">(4.1)</a> is solvable if and only if the <span class="math inline">\(v_\mu\)</span> consistency conditions <a href="IV.html#eq:iv-snf-equi-sys-vpart">(4.16)</a>
<span class="math display">\[
  0=f_3(t)
\]</span>
are fulfilled.</p></li>
<li><p>An initial condition <a href="IV.html#eq:iv-ltv-inicond">(4.2)</a> is consistent if, and only if, in the the <span class="math inline">\(a_\mu\)</span> conditions
<span class="math display">\[
0=x_2(t_0) + f_2(t_0)
\]</span>
related to <a href="IV.html#eq:iv-snf-equi-sys-apart">(4.15)</a> hold.</p></li>
<li>The corresponding initial value problem <a href="IV.html#eq:iv-ltv-dae">(4.1)</a>–<a href="IV.html#eq:iv-ltv-inicond">(4.2)</a> is uniquely solvable if, and only if, in addition <span class="math inline">\(u_\mu=0\)</span>, i.e., <span class="math inline">\(x_3\)</span> is not present in <a href="IV.html#eq:iv-snf-equi-sys-dpart">(4.14)</a>.</li>
</ol>
</div>


<div class="JHSAYS">
<p>Just by comparing the solvability conditions with those for the constant coefficient case, e.g. Theorem <a href="III.html#thm:regularity-means-solvability">3.3</a>, we can observe that</p>
<ol style="list-style-type: decimal">
<li>that <span class="math inline">\(\mu \sim \nu -1\)</span> (unless <span class="math inline">\(\nu =0\)</span>) and</li>
<li>a matrix pair is regular if <span class="math inline">\(u_\mu = v_\mu = 0\)</span>.</li>
</ol>
</div>

</div>
<div id="derivative-arrays" class="section level2">
<h2><span class="header-section-number">4.4</span> Derivative Arrays</h2>
<p>The concept and the derivation of the <em>strangeness index</em> gives a complete characterization of solvability of linear DAEs with time-varying coefficients (provided sufficient regularity of the coefficients and the right hand side). However, for practical considerations there are two shortcomings</p>
<ol style="list-style-type: decimal">
<li><p>The formulation through the canonical form is very implicit and requires the derivatives of computed quantities (like the <span class="math inline">\(\dot V_2\)</span> in the proof of Theorem <a href="IV.html#thm:global-canonical-form">4.3</a>).</p></li>
<li><p>There is no direct generalization to nonlinear systems.</p></li>
</ol>
<p>Both these issues are better addressed in the approach to a <em>strangeness free</em> form like through <em>derivative arrays</em>.</p>
<p>For that, we consider the DAE
<span class="math display">\[
E(t) \dot x = A(t) x+f
\]</span>
differentiate it
<span class="math display">\[
E(t) \ddot x(t) + \dot E(t) \dot x(t) = \dot A(t) x + A(t) \dot x+\dot f,
\]</span>
and add these equations to the system to obtain the inflated DAE
<span class="math display">\[
\begin{bmatrix}
E &amp; 0\\
\dot E - A &amp; E 
\end{bmatrix}
\frac{d}{dt}
\begin{bmatrix}
x \\ \dot x
\end{bmatrix} =
\begin{bmatrix}
A &amp; 0\\
\dot A &amp; 0 
\end{bmatrix}
\begin{bmatrix}
x \\ \dot x
\end{bmatrix}
+
\begin{bmatrix}
f \\ \dot f
\end{bmatrix}.
\]</span></p>
<p>If we add also the second derivative of the equations, we obtain
<span class="math display">\[
\begin{bmatrix}
E &amp; 0 &amp; 0\\
\dot E - A &amp; E &amp;0  \\
\ddot E - 2A &amp; 2\dot E -A &amp;E 
\end{bmatrix}
\frac{d}{dt}
\begin{bmatrix}
x \\ \dot x \\ \ddot x
\end{bmatrix} =
\begin{bmatrix}
A &amp; 0 &amp; 0\\
\dot A &amp; 0 &amp; 0\\
\ddot A &amp; 0  &amp; 0
\end{bmatrix}
\begin{bmatrix}
x \\ \dot x \\ \ddot x
\end{bmatrix}
+
\begin{bmatrix}
f \\ \dot f \\ \ddot f
\end{bmatrix}.
\]</span></p>
If we do this <span class="math inline">\(\ell\)</span> times, we arrive at the so-called <em>derivative array</em>

<div class="definition">
<p><span id="def:iv-derivative-array" class="definition"><strong>Definition 4.4  </strong></span>Consider the DAE <a href="IV.html#eq:iv-ltv-dae">(4.1)</a> and let <span class="math inline">\(E\)</span>, <span class="math inline">\(A\)</span>, <span class="math inline">\(f\)</span> be <span class="math inline">\(\ell\)</span>-times differentiable for some integear <span class="math inline">\(\ell\geq 0\)</span>. Then the <em>derivative array</em> of order <span class="math inline">\(\ell\)</span> is given as
<span class="math display">\[\begin{equation}
M_\ell (t) \dot z_\ell(t) = N_\ell (t) z_\ell(t) + g_\ell(t),
\end{equation}\]</span>
where
<span class="math display">\[
(M_\ell)_{i,j} = \binom{i}{j}E^{(i-j)} - \binom{i}{j+1}A^{(i-j-1)}, \quad i,j=1,\dotsc,\ell,
\]</span></p>
<p>where
<span class="math display">\[
(N_\ell)_{i,j} = 
\begin{cases}
A^{(i)}, \quad &amp;\text{for } i=1,\dotsc, \ell, \, j=0 \\
0, \quad &amp; \text{else}
\end{cases},
\]</span></p>
<p>and where</p>
<span class="math display">\[
z_\ell = \begin{bmatrix}
x \\ \dot x \\ \vdots \\ x^{(\ell)}
\end{bmatrix}, \quad
g_\ell = \begin{bmatrix}
f \\ \dot f \\ \vdots \\ f^{(\ell)}
\end{bmatrix}.
\]</span>
</div>


<div class="JHSAYS">
<ul>
<li>By construction, any solution <span class="math inline">\(x\)</span> that solves the derivative array, solves the DAE and vice versa.</li>
<li>The <em>strangeness-free</em> form from above is an equivalent system too with <span class="math inline">\(d_\mu\)</span> differential relations, <span class="math inline">\(a_\mu\)</span> algebraic equations, and <span class="math inline">\(v_\mu\)</span> redundant (or consistency) relations.</li>
<li>Next, we will show that from the derivative array we can extract <span class="math inline">\(d_\mu\)</span> differential and <span class="math inline">\(a_\mu\)</span> well separated algebraic relations for <span class="math inline">\(x\)</span>, i.e. an equivalent strangeness free form.</li>
</ul>
</div>

<p>The following theorem connects the derivative array to the strangeness index and provides a <em>strangeness free</em> reformulation of the DAE <a href="IV.html#eq:iv-ltv-dae">(4.1)</a>.</p>

<div class="theorem">
<p><span id="thm:iv-derivative-arrays-projections" class="theorem"><strong>Theorem 4.6  </strong></span>Let the strangeness index of the pair <span class="math inline">\((E, A)\)</span> of matrix-valued functions be well defined according to <a href="IV.html#def:iv-strangeness-index">4.3</a> with the global invariants <span class="math inline">\(d_\mu\)</span>, <span class="math inline">\(a_\mu\)</span>, <span class="math inline">\(v_\mu\)</span>. Then for the derivative array as defined in Definition <a href="IV.html#def:iv-derivative-array">4.4</a> it holds that</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\operatorname{corank}M_{\mu+1}- \operatorname{corank}M_\mu = v_\mu\)</span></p></li>
<li><p><span class="math inline">\(\operatorname{rank}M_\mu(t) = (\mu+1)m-a_\mu - v_\mu\)</span> on <span class="math inline">\(\mathcal I\)</span>, and there exists a smooth matrix function <span class="math inline">\(Z_{2,3}\)</span> (that spans the left null space of <span class="math inline">\(M_\mu\)</span>) with
<span class="math display">\[
 Z_{2,3}^H M_\mu(t) =0.
\]</span></p></li>
<li>The projection <span class="math inline">\(Z_{2,3}\)</span> can be partitioned into two parts:
<ul>
<li><span class="math inline">\(Z_3\)</span> (left nullspace of <span class="math inline">\((M_\mu, N_\mu)\)</span>) so that <span class="math display">\[Z_3^HN_\mu(t) =0\]</span>.</li>
<li><span class="math inline">\(Z_2\)</span> such that
<span class="math display">\[
Z_2^HN_\mu 
\begin{bmatrix}
I_n \\ 0 \\ \vdots \\ 0 
\end{bmatrix}
=
Z_2^H
\begin{bmatrix}
A \\ \dot A \\ \vdots \\ A^{(\mu)}
\end{bmatrix}
 =:\hat A_2
\]</span>
has full rank.</li>
</ul></li>
<li>Furthermore, let <span class="math inline">\(T_2\)</span> be a smooth matrix function such that <span class="math inline">\(\hat A_2 T_2=0\)</span> (right nullspace of <span class="math inline">\(\hat A_2\)</span>). Then
<span class="math display">\[
\operatorname{rank}E(t) T_2 = d_\mu
\]</span>
and there exists a smooth matrix function <span class="math inline">\(Z_1\colon \mathcal I \to \mathbb C^{n,d_\mu}\)</span> with <span class="math display">\[\operatorname{rank}(Z_1^TE) = d_\mu.\]</span>
We define <span class="math inline">\(Z_1^HE=\hat E_1\)</span>.</li>
</ol>
</div>


<div class="proof">
 <span class="proof"><em>Proof. </em></span> Kunkel/Mehrmann: Thm. 3.29, Thm. 3.30, Thm. 3.32.
</div>

<p>A few observations and implications:</p>
<ul>
<li><p><span class="math inline">\(Z_{2,3}^H\)</span> operates on the derivative array
<span class="math display">\[
  M_\ell (t) \dot z_\ell(t) = N_\ell (t) z_\ell(t) + g_\ell(t),
\]</span></p></li>
<li>Specifically, it picks out all constraint equations including the redundancies (<span class="math inline">\(Z_3^H\)</span>) and all explicit and hidden constraints (<span class="math inline">\(Z_2^H\)</span>).</li>
<li><p><span class="math inline">\(Z_1^H\)</span> operates on the original system
<span class="math display">\[
E(t)\dot x = A(t)x + f(t)
\]</span>
and picks out the dynamic part.</p></li>
</ul>
<p>By means of the projections defined in Theorem <a href="IV.html#thm:iv-derivative-arrays-projections">4.6</a>, one can define (Kunkel/Mehrmann: Theorem 3.32) a <em>strangeness-free</em> condensed form</p>
<p><span class="math display" id="eq:iv-cndnsd-snff-vpart" id="eq:iv-cndnsd-snff-apart" id="eq:iv-cndnsd-snff-dpart">\[\begin{align}
\hat E_1(t) \dot x(t) &amp;= \hat A_{1}(t)x(t) + \hat f_1(t) \tag{4.17} \\
0 &amp;= \hat A_2 x_2(t) + \hat f_2(t) \tag{4.18}\\
0 &amp;= \hat f_3(t), \tag{4.19}
\end{align}\]</span></p>
<p>where
<span class="math display">\[
\hat E_1(t) := Z_1(t)^HE(t) \in \mathbb C^{d_\mu, n}, \quad \hat A_1(t) := Z_1^H(t)A (t)\in \mathbb C^{d_\mu, n}, \quad \hat f_1(t) = Z_1^Hf(t) \in \mathbb C^{d_\mu},
\]</span>
where
<span class="math display">\[
\hat A_2(t) = Z_2(t)^H
     \begin{bmatrix}
     A(t) \\ \dot A(t) \\ \vdots \\ A^{(\mu)(t)}
     \end{bmatrix}
\in \mathbb C^{a_\mu, n}, 
\quad
\hat f_2(t) = Z_2^Hg_\mu(t) \in \mathbb C^{a_\mu},
\quad
\]</span>
and where
<span class="math display">\[
\hat f_3(t) = Z_3^Hg_\mu(t) \in \mathbb C^{(\mu+1)m-a_\mu-d_\mu}.
\]</span></p>
<p><strong>Remark</strong>: This condensed equivalent strangeness free form <a href="IV.html#eq:iv-cndnsd-snff-dpart">(4.17)</a>–<a href="IV.html#eq:iv-cndnsd-snff-vpart">(4.19)</a> comes with a number of advantages over the one defined in Theorem <a href="IV.html#thm:iv-strangeness-free-equiv-system">4.5</a>.</p>
<ol style="list-style-type: decimal">
<li><p>It can be derived by only differentiating the given functions <span class="math inline">\(E\)</span>, <span class="math inline">\(A\)</span>, and <span class="math inline">\(f\)</span>. This is much preferable since a given function can be evaluated with high accuracy (which is needed for computing derivatives numerically) or can be even differentiated analytically.</p></li>
<li><p>It is formulated in the original variable <span class="math inline">\(x\)</span> – no state transformation involved.</p></li>
<li><p>It can be generalized to nonlinear systems.</p></li>
</ol>
<p><strong>Example 1</strong> Cp. Examples 3.33 and 3.34 in Kunkel/Mehrmann that provide the strangeness free forms for the motivating examples of this section.</p>
<p><strong>Example 2</strong> Compute the forms for the incompressible Navier-Stokes equations (to be provided).</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="III.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="numerical-approximation-of-daes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DAEs.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
